<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<title>MADAI Distribution-Sampling Tutorial</title>
<style>
div.wide { color:black; background-color:white; margin-left:0.5em;
	margin-right:0.5em; padding:0.5em; }
body {
	font-family:sans-serif; text-align:center;  }
code { color:#001A57;background-color:#ffffff;}
pre .input { color:#001A57; background-color:#f0f0f0; }
pre { color:#000000; background-color:#f0f0f0;
	overflow:auto; overflow-y:visible;
	border-left:2px #dddddd solid; margin-left:15px;
	padding-left:10px; padding-top:2px; padding-bottom:2px;
	margin-top:3px; margin-bottom:3px; z-index:12; }
table { border-collapse:collapse; }
th { color:black; background-color:#f0f0f0;}
td,th { border:1px black solid; text-align:left}
hr { width:100%; background-color:#56A0D3; color:#001A57;
	border:0;height:1px; margin:0}
.centered {text-align:center;}
.cbracket { color:#440044; background-color:#f0f0f0;
	text-decoration:none; font-weight:bold; }
.comment { color:#880000; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.function { color:#008800; background-color:#f0f0f0;
	text-decoration:none; font-weight:bold; }
.keyword { color:#000088; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.normal { color:#000000; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.number { color:#224466; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.preproc { color:#444400; background-color:#f0f0f0;
	text-decoration:underline; font-weight:normal; }
.specialchar { color:#004488; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.string { color:#004444; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.symbol { color:#008844; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.type { color:#444444; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
</style>
</head>
<body>

<p style="text-align:center"><b>Options in <code>settings.dat</code></b></p>
<table style="width:100%">
<tr><th>Variable Name<br>Default Value</th><th>Meaning</th></tr>
<tr><td><code>MODEL_OUTPUT_DIRECTORY</code><br>model_output</td>
  <td><p>The directory (relative to the working directory) where the model inputs and outputs can be found.</p></td></tr>
<tr><td><code>EXPERIMENTAL_RESULTS_DIRECTORY</code><br>experimental_results</td>
  <td><p>The directory (relative to the working directory) where the experimental observations can be found.</p></td></tr>
<tr><td><code>GENERATE_TRAINING_POINTS_NUMBER_OF_POINTS</code><br>100</td>
  <td><p>The number of training points generated by <code>generateTrainingPoints</code></p></td></tr>
<tr><td><code>GENERATE_TRAINING_POINTS_PERCENTILE_PARTITION</code><br>1</td>
  <td><p>If the prior distribution for a parameter is not uniform, should the training points be percentiles from the distribution, or should they be evenly spaced?</p></td></tr>
<tr><td><code>GENERATE_TRAINING_POINTS_STANDARD_DEVIATIONS</code><br>3</td>
  <td><p>If the prior distribution for a parameter is Gaussian, how far out should the uniformly-spaced sampled points go?</p></td></tr>
<tr><td><code>PCA_FRACTION_RESOLVING_POWER</code><br>0.95</td>
  <td><p>When <code>basicTrain</code> is deciding how many principal components to retain, it considers the total resolving power of the model.  The resolving power of a single principal component is &radic;(1 + &lambda;[i]), where &lambda;[i] is the eigenvalue associated with that variable.  The total resolving power is the product the resolving powers of all of the components.  <code>basicTrain</code> will retain enough components to keep this fraction of the resolving power.
</p></td></tr>
<tr><td><code>EMULATOR_COVARIANCE_FUNCTION</code><br><code>SQUARE_EXPONENTIAL_FUNCTION</code></td>
  <td><p>See <a href="CovarianceFunctions.pdf">Covariance Functions</a></p></td></tr>
<tr><td colspan="3"><img src="images/kernel_functions.png"></td></tr>
<tr><td><code>EMULATOR_REGRESSION_ORDER</code><br>1</td>
  <td><p>The assumed functional form of the model before Gaussian Process Emulation.  This is the order of the polynomial.  0, 1, 2,or 3. </p></td></tr>
<tr><td><code>EMULATOR_NUGGET</code><br>0.001</td>
  <td><p>See <a href="CovarianceFunctions.pdf">Covariance Functions</a></p></td></tr>
<tr><td><code>EMULATOR_AMPLITUDE</code><br>1</td>
  <td><p>See <a href="CovarianceFunctions.pdf">Covariance Functions</a></p></td></tr>
<tr><td><code>EMULATOR_SCALE</code><br>0.01</td>
  <td><p>See <a href="CovarianceFunctions.pdf">Covariance Functions</a>.  The final value ofr each parameter's scale will be <code>EMULATOR_SCALE</code> times the width of the middle two quartiles of that parameter's prior distribution.</p></td></tr>
<tr><td><code>MCMC_NUMBER_OF_SAMPLES</code><br>100</td>
  <td><p>How many samples should <code>generateMCMCtrace</code> produce.  The default is small for testing purposes.  Values around 10<sup>6</sup> are recommended.</p></td></tr>
<tr><td><code>MCMC_NUMBER_OF_BURN_IN_SAMPLES</code><br>0</td>
  <td><p>The number of MCMC samples to be discarded at the beginning
  of the MCMC run.</p></td></tr>
<tr><td><code>MCMC_USE_EMULATOR_COVARIANCE</code><br>0</td>
  <td><p>Should the variance returned by the Gaussian Process Emulator be used in the likelihood calculation?</p></td></tr>
<tr><td><code>MCMC_STEP_SIZE</code><br>0.1</td>
  <td><p>How big should each step be in the Metropolis Hastings
  algorithm?  (This will be scaled by the characteristic length of
  each parameter's prior distribution)</p></td></tr>
</table>
</body>
</html>
