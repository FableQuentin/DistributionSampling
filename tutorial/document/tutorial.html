<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<title>MADAI Distribution Sampling Tutorial</title>
<style>
div.column { color:black; background-color:white; margin-left:auto;
	margin-right:auto; margin-top:0px; margin-bottom:0px;
	max-width:872px; text-align:left; padding:8px 8px 8px 8px;
	border:1px solid #56A0D3; }
div.box { margin: 16px 2em;; border:2px solid #56A0D3;
		padding:0 0.5ex;  }
div.box p { margin: 0px 0; padding: 8px 0; }
div.wide { color:black; background-color:white; margin-left:0.5em;
	margin-right:0.5em; padding:0.5em; }
body { color:#000000; background-color:#56A0D3; padding:0; margin:0;
	font-family:sans-serif; text-align:center; background-repeat:
	repeat; background-attachment:fixed; background-size:cover; }
code { color:#001A57;background-color:#ffffff;}
pre .input { color:#001A57; background-color:#f0f0f0; }
pre { color:#000000; background-color:#f0f0f0;
	overflow:auto; overflow-y:visible;
	border-left:2px #dddddd solid; margin-left:15px;
	padding-left:10px; padding-top:2px; padding-bottom:2px;
	margin-top:3px; margin-bottom:3px; z-index:12; }
table { border-collapse:collapse; }
th { color:black; background-color:#f0f0f0;}
td,th { border:1px black solid; text-align:left}
hr { width:100%; background-color:#56A0D3; color:#001A57;
	border:0;height:1px; margin:0}
.centered {text-align:center;}
.cbracket { color:#440044; background-color:#f0f0f0;
	text-decoration:none; font-weight:bold; }
.comment { color:#880000; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.function { color:#008800; background-color:#f0f0f0;
	text-decoration:none; font-weight:bold; }
.keyword { color:#000088; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.normal { color:#000000; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.number { color:#224466; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.preproc { color:#444400; background-color:#f0f0f0;
	text-decoration:underline; font-weight:normal; }
.specialchar { color:#004488; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.string { color:#004444; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.symbol { color:#008844; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.type { color:#444444; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
</style>
<script>
function toggleViz(name) {
  var e = document.getElementById(name);
  if(e.style.display == 'block') {
    e.style.display = 'none';
  } else {
    e.style.display = 'block';
  }
  return false;
}
</script>
</head>
<body>
<div class="column">
<!--=========================================================================-->
<h1>MADAI Distribution Sampling Tutorial</h1>

<hr>
<p><strong>Contents</strong></p>
<ul style="list-style-type:none;">
<li>0. <a href="#Introduction">Introduction</a></li>
<li>1. <a href="#Installing">Installing Software</a></li>
		<ul style="list-style-type:none;">

		<li>a. <a href="#DST">The Distribution Sampling Tools</a></li>
		<li>b. <a href="#other">Other software</a></li>
		</ul>
<li>2. <a href="#Running">Running the Software </a></li>
		<ul style="list-style-type:none;">
		<li>a. <a href="#Fast">Markov chain Monte Carlo with a Fast 			Model</a></li>
		<li>b. <a href="#Slow">Use an Emulator for a Slow Model</a></li>
		</ul>
<li>3. <a href="#Visualizing">Visualizing the Results</a></li>

</ul>

<hr>

<!--=========================================================================-->
<h2 id="Introduction">0. Introduction</h2>

<p>This software will enable you to determine model parameters from
comparing model outputs to a set of experimental measurements to
  determine the relative likelihood of a set of parameter values.</p>

<p>Before starting, You will need to build an effectively parametrized
 model.  Decide which parameters you want to vary in your model and
 what you think the prior distribution of each parameter is (this may
 be as simple as a uniform distribution between <code>value_min</code>
 and <code>value_max</code>).</p>

<p>Next, decide which model outputs you want to use.  These should be
numbers which can be readily compared to your experimental/
  observational data.</p>

<p><img src="images/MADAI_Stats_and_Vis2.png" alt=""></p>

<!-- \todo insert background for what we want to accomplish -->

<!--=========================================================================-->
<h2 id="Installing">1. Installing Software</h2>

<h3 id="DST">1a. The Distribution Sampling Tools</h3>

<ol>
  <li>Install the prerequisite packages
  (<a href="http://www.cmake.org/cmake/resources/software.html">CMake</a>,
  <a href="http://www.boost.org/users/download/">Boost</a>,
  <a href="http://eigen.tuxfamily.org/">Eigen3</a>):
	<ul>
	  <li>Ubuntu/Debian-based:
		<pre>
$ <span class="input">sudo apt-get -y install \
    build-essential \
    cmake \
    libboost-dev \
    libeigen3-dev \
    gnuplot</span></pre>
	  </li>
	  <li>Red Hat-based:
<pre>
$ <span class="input">sudo yum -y groupinstall "Development Tools"</span>
$ <span class="input">sudo yum -y install \
    cmake \
    boost-devel \
    eigen3-devel \
    gnuplot</span></pre>
	  </li>
	  <li>MacOS 10.x with macports:
	    <pre>$ <span class="input">port install cmake boost eigen3 gnuplot</span></pre>
	  </li>
	</ul>
  </li>
  <li>Download the file <code>DistributionSampling-VERSION.tgz</code> from <a href="https://madai-public.cs.unc.edu/statistical-tools/distribution-sampling-library/">the MADAI web site</a>.</li>
  <li>Extract

<pre>
$ <span class="input">tar -x -z -f .../DistributionSampling.tar.gz</span></pre></li>
  <li>Build and install.  In this example, we will install in <code>${HOME}/local</code>.
<pre>
$ <span class="input">DistributionSampling/build.sh "${HOME}/local"</span></pre>
  </li>
</ol>

<div class="box">
<p><em>Aside:</em> MacOS 10.x users who do not have macports and need Boost or Eigen3 can still install this library.  You must get CMake
from <a href="http://www.cmake.org/cmake/resources/software.html#latest">www.cmake.org</a>. Then run the command:</p>
<pre>
$ <span class="input">DistributionSampling/full_build.sh "${HOME}/local"</span></pre>
<p>This will download the necessary Boost and Eigen3 headers into a temporary directory for the compilation. </p>
</div>

<div class="box">
<p><em>Aside:</em> The <code>build.sh</code>
and <code>full_build.sh</code> scripts simply call CMake.  You can
also run CMake directly.</p>
<pre>
$ <span class="input">mkdir build</span>
$ <span class="input">cd build</span>
$ <span class="input">cmake "../DistributionSampling" \
    -DCMAKE_INSTALL_PREFIX:PATH="${HOME}/local" \
    -DBoost_INCLUDE_DIR:PATH="/usr/include" \
    -DEIGEN3_INCLUDE_DIR:PATH="/usr/include/eigen3" \
    -DCMAKE_BUILD_TYPE:STRING=Release \
    -DBUILD_TESTING:BOOL=0 \
    -DUSE_OPENMP:BOOL=0 \
    -DUSE_GPROF:BOOL=0</span>
$ <span class="input">make</span>
$ <span class="input">make install</span>
$ <span class="input">PATH=&quot;${PATH}:${HOME}/local/bin&quot;</span>
</pre></div>

<p>Your executables will be in the
directory <code>${HOME}/local/bin</code>. You can
make these executables available by including this directory in your
path:</p>
<pre>$ <span class="input">PATH=&quot;${PATH}:${HOME}/local/bin&quot;</span></pre>

<div class="box">
<p><em>Aside:</em> csh/tcsh users:</p>
<pre>&gt; <span class="input">set path = ($path &quot;${HOME}/local/bin&quot;)</span></pre>
</div>

<div class="box">
<p><em>Aside:</em> If you wish to compile your own software that links against the library, the include files are in <code>${HOME}/local/include</code> and the library is in <code>${HOME}/local/lib/madai</code> . </p></div>

<h3 id="other">1b. Other software</h3>

This additional software may be useful to you. Except for Python, none of it is required for the tutorial.

<ul>
<li>Python (used in tutorial examples) &mdash;
	<a href="http://www.python.org/">python.org/</a>

<li>MADAI Workbench (customized ParaView) <a href="http://vis.madai.us/">http://vis.madai.us</a></li>

<li>ParaView &mdash; <a href="http://www.paraview.org/paraview/resources/software.php">paraview.org</a>
<pre>$ <span class="input">sudo apt-get -y install paraview</span></pre>
<pre>$ <span class="input">sudo yum -y install paraview</span></pre>
</li>

<li>GGobi &mdash; <a href="http://www.ggobi.org/downloads/">ggobi.org</a>
<pre>$ <span class="input">sudo apt-get -y install ggobi</span></pre>
<pre>$ <span class="input">sudo yum -y install ggobi</span></pre>
</li>

</ul>

<!--=========================================================================-->
<h2 id="Running">2. Running the Software</h2>
<h3 id="Fast">2a. Markov chain Monte Carlo with a Fast Model</h3>

<p>By a "fast model" we mean that you can wait while it runs millions
of times.</p>

<p>You will need to build an executable program to interface with
  the <code>madai_generate_trace</code> program.</p>

<p><code>madai_generate_trace</code> will call your executable
and interactively query it for model outputs at given parameter
vectors.</p>

<div class="box">
<p><em>Aside:</em> The Interactive Model Language.</p>
<ol>
<li>First the <strong>external model</strong> (your program) will
output on standard output (stdout) a list of comments (each beginning with a '#' and ending with a '\n').</li>
<li>Then it will output the string &quot;VERSION 1 \n&quot;</li>
<li>Then it will output the string &quot;PARAMETERS <em>Nparam</em>
\n&quot;, where <em>Nparam</em> is the number of parameters.</li>
<li>Then, for each parameter, it will output the name of the parameter
(a string without whitespace), whitespace, the prior distribution, and
'\n'
<ul>
<li>A uniform prior distribution is in the format &quot;UNIFORM <em>MIN</em> <em>MAX</em>&quot;</li>
<li>A Gaussian prior distribution is in the format &quot;GAUSSIAN <em>MEAN</em> <em>STDDEV</em>&quot;</li>
</ul></li>
<li>Then the string &quot;OUTPUTS <em>Nouts</em> \n&quot;, where <em>Nouts</em> is the number of outputs.</li>
<li>Then, for each parameter, it will output the name of the output (a string without whitespace), followed by a '\n'</li>
<li>Then it either outputs:
<ul>
  <li>&quot;VARIANCE <em>Nouts</em> \n&quot; (<em>Nouts</em> is still the number of outputs), <br>or</li>
  <li>&quot;COVARIANCE TRIANGULAR_MATRIX <em>M</em> \n&quot;, where <em>M</em>=<em>Nouts</em>&times;(<em>Nouts</em>+1)/2)<br>or</li>
  <li>&quot;COVARIANCE FULL_MATRIX <em>K</em> \n&quot;, where <em>K</em>=<em>Nouts</em>^<sup>2</sup></li>
</ul></li>
<li>The external model them prints &quot;END_OF_HEADER \n&quot; </li>
<li>The external model will then wait for <em>Nparam</em> ASCII-encode floating-point numbers on standard input.  These will be interpreted as a set of parameter values.</li>
<li>The external model should calculate model outputs at that point in parameter space, as well as (co)variance.  It will then print those numbers (ASCII-encoded) onto standard output.  Remember to flush standard out after writing.</li>
<li>The external model should then wait for the next set of parameters and repeat the output calculation</li>
<li>The external model should exit when it reads the string &quot;STOP&quot; or end-of-file or received an interrupt signal.</li>
</ol>
</div>

<p>Our example will be the parabolic potential model.  This
model has the parameters <code>X0</code>, <code>K</code>, and <code>TEMP</code>;
and the observables <code>MEAN_X</code>, <code>MEAN_X_SQUARED</code>, and
<code>MEAN_ENERGY</code>.  Here's what the preamble of the interactive
program looks like:</p>

<pre>
$ <span class="input">python parabolic_interactive.py</span>
# ParabolicPotentialModel
VERSION 1
PARAMETERS 3
X0	UNIFORM	-2.0	2.0
K	UNIFORM	0.5	4.0
TEMP	UNIFORM	0.5	10.0
OUTPUTS 3
MEAN_X
MEAN_X_SQUARED
MEAN_ENERGY
VARIANCE 3
END_OF_HEADER
<span class="input">STOP</span></pre>

<p>The external model then waits for a list of parameter values
(encoded as text) on stdin.  Then it returns the model outputs
followed by the model covariances.  For example:

<pre>
<span class="input">0.0 2.25 5.25</span>
0.0 1.166666666666667 5.250000000000001
1.0801234497346435 1.6499158227686113 3.712310601229375
</pre>

<p>The <code>parabolic_interactive.py</code> program can be found in the directory <code>DistributionSampling/tutorial/parabolic_example/</code></p>

<p>First move into the <code>DistributionSampling/tutorial</code> directory.</p>
<pre>$ <span class="input">cd ..../DistributionSampling/tutorial</span></pre>
<p>Then make a working directory:</p>
<pre>$ <span class="input">mkdir -p parabolic_ext</span></pre>
<pre>$ <span class="input">cd parabolic_ext</span></pre>

<p>(From here on out, we will assume that you are in your working
directory and will refer to it as <code>.</code> (a single dot).)</p>

<p>Next, copy the “experimental” results file into the working directory.  This specifies all of the experimentally observed measurements and errors. (If you skip that step, it assumes that the measurements are 0.0 and the error is 1.0.)
</p>
<pre>$ <span class="input">cp ../parabolic_example/experimental_results.dat .</span>
$ <span class="input">cat experimental_results.dat</span>
MEAN_X         1.0          0.6
MEAN_X_SQUARED 1.411764706  1.4
MEAN_ENERGY    2.8          1.9
</pre>

<p>Next, we  will create a <code>settings.dat</code> file in
  this directory with some default values in it. All of the
  DistributionSampling utilities will look for this file.</p>
<pre>$ <span class="input">madai_print_default_settings &gt; ./settings.dat</span></pre>

<div class="box">
<p><em>Aside:</em> A detailed description of the options in <code>settings.dat</code> can be found in the manual.</p></div>

<p>Now use you favorite text editor to edit the settings.dat file. Set
the variable EXTERNAL_MODEL_EXECUTABLE to
../parabolic_example/parabolic_interactive.py .
Alternatively, use the <code>madai_set_variable</code> program:
</p>

<pre>
$ <span class="input">madai_set_variable . EXTERNAL_MODEL_EXECUTABLE \
    &quot;../parabolic_example/parabolic_interactive.py&quot;</span></pre>

<!--
<pre>
$ <span class="input">KEY=&quot;EXTERNAL_MODEL_EXECUTABLE&quot;</span>
$ <span class="input">VAL=&quot;../parabolic_example/parabolic_interactive.py&quot;</span>
$ <span class="input">sed -i &quot;s#^[[:space:]]*${KEY}\([[:space:]].*\)*\$#${KEY} ${VAL}#&quot; ./settings.dat</span></pre>
-->

<p>The final step is to run the Markov chain Monte Carlo (MCMC)
routine on your model.  The <code>madai_generate_trace</code> program
uses the external model to produce model outputs for points in
parameter space.  These model outputs are compared to the experimental
values to calculate likelihood.</p>

<p class="centered"><em>L</em> &#8733; exp((-0.5) &times; sum((
(<em>Y<sub>_observed</sub></em>[<em>i</em>] - <em>Y<sub>_model</sub></em>[<em>i</em>]) /
&sigma;[<em>i</em>] ))^<sup>2</sup>)</p>

<p class="centered">ln(<em>L</em>) = C - 0.5 &times; sum((
(<em>Y<sub>_observed</sub></em>[<em>i</em>] - <em>Y<sub>_model</sub></em>[<em>i</em>]) /
&sigma;[<em>i</em>] )^<sup>2</sup>)</p>

<p>The Metropolis-Hastings MCMC algorithm is used to draw a large
number of samples from the distribution proportional to likelihood.
These values are stored in a comma-separated-value (csv) file
specified in the arguments.</p>

<pre>
$ <span class="input">madai_generate_trace . &quot;mcmc.csv&quot;</span>
</pre>

<p>The output file is left in the <code>trace</code> directory:</p>

<pre>
$ <span class="input">head trace/mcmc.csv</span>
&quot;X0&quot;,&quot;K&quot;,&quot;TEMP&quot;,&quot;MEAN_X&quot;,&quot;MEAN_X_SQUARED&quot;,&quot;MEAN_ENERGY&quot;,&quot;LogLikelihood&quot;
-0.687954,3.69012,3.48753,-0.687954,0.945831,3.48753,-11.6557
-0.68372,3.76719,3.42022,-0.68372,0.921423,3.42022,-11.3976
-0.71932,3.75696,3.38807,-0.71932,0.968327,3.38807,-11.3574
-0.624684,3.82671,3.49921,-0.624684,0.847438,3.49921,-11.5668
-0.648931,3.91341,3.55124,-0.648931,0.874838,3.55124,-11.7892
-0.653541,3.92884,3.58919,-0.653541,0.883891,3.58919,-11.9357
-0.626959,3.95924,3.46898,-0.626959,0.831164,3.46898,-11.4492
-0.626959,3.95924,3.46898,-0.626959,0.831164,3.46898,-11.4492
-0.542122,3.93226,3.24617,-0.542122,0.706659,3.24617,-10.5558
</pre>

<p>The <code>madai_generate_trace</code> program will produce the
 number of points specified in the <code>settings.dat</code> under in
 the <code>SAMPLER_NUMBER_OF_SAMPLES</code> variable.  Depending on the
 number of the parameters, a larger or smaller number of samples will
 need to be drawn.  Once you are sure that the program is working
 correctly, set <code>SAMPLER_NUMBER_OF_SAMPLES</code> to a large number
 (a million or ten million) and let the program run for a
 while.</p>

<p>Suppose we set <code>SAMPLER_NUMBER_OF_SAMPLES</code> to <code>1000000</code> and wish to sub-sample the distribution for analysis or visualization.  The <code>madai_subsample_text_file</code> will sample every <em>N</em>th point from a csv file into a new csv file.

<pre>$ <span class="input">madai_subsample_text_file 20 trace/mcmc.csv trace/mcmc_50000.csv</span></pre>

<div class="box">
<p><em>Aside:</em> A faster way to interface with the DistributionSampling library is to link directly to it. For a complete example, look in the <code>DistributionSampling/tutorial/examples/ParabolicPotentialModelCxx</code> directory.</p>
<p>A skeleton for your own C++ model can be found in <code>DistributionSampling/tutorial/examples/MCMC_Example</code> .
</div>

<!--=========================================================================-->
<h3 id="Slow">2b. Use an Emulator for a Slow Model</h3>

<p>The DistributionSampling library uses a Gaussian Process Emulator
to emulate a slow model much more quickly.  To train the Emulator, the
software requires hundreds of sample points.  At each training point,
you will need the parameter values and the model outputs.</p>

<p> We will use the parabolic potential model as an example again.
  This model has the parameters <code>X0</code>, <code>K</code>,
  and <code>TEMP</code>; and the observables <code>MEAN_X</code>,
  <code>MEAN_X_SQUARED</code>, and <code>MEAN_ENERGY</code>.</p>

<p>The <code>parabolic_evaluate.py</code> program can be found in the directory <code>DistributionSampling/tutorial/parabolic_example/</code></p>

<p>First move into the <code>DistributionSampling/tutorial</code> directory.</p>
<pre>$ <span class="input">cd ..../DistributionSampling/tutorial</span></pre>
<p>Then make a working directory:</p>
<pre>$ <span class="input">mkdir -p parabolic_emu</span></pre>
<pre>$ <span class="input">cd parabolic_emu</span></pre>

<p>From here on out, we will assume that you are in your working
directory and will refer to it as <code>.</code> (a single dot).</p>

<p>The first thing we will do is create a <code>setting.dat</code>
file in this directory with some default values in it. All of the
DistributionSampling utilities will look for this file.</p>

<pre>$ <span class="input">madai_print_default_settings &gt; ./settings.dat</span></pre>

<div class="box">
<p><em>Aside:</em> A detailed description of the options in <code>settings.dat</code> can be found in the manual.</p></div>

<p>Next, we need to create a parameter_priors.dat file that contains
our assumptions about prior probability distribution for the values
for the parameters.

<pre>$ <span class="input">cp ../parabolic_example/parameter_priors.dat .</span>
$ <span class="input">cat parameter_priors.dat</span>
uniform X0   &#0045;2.0 2.0
uniform K    0.5  4.0
uniform TEMP 0.5  10.0
</pre>

<p>Next we will specify all of the experimentally observed
measurements and errors:</p>

<pre>$ <span class="input">cp ../parabolic_example/experimental_results.dat .</span>
$ <span class="input">cat experimental_results.dat</span>
MEAN_X         1.14           0.1
MEAN_X_SQUARED 2.77634418605  0.1
MEAN_ENERGY    3.4925         0.1
</pre>

<p>Finally, we create a file that contains the list of observables
that we want to make use of.  This should be a subset
of <code>results.dat</code>.</p>

<pre>$ <span class="input">cp ../parabolic_example/observable_names.dat .</span>
$ <span class="input">cat observable_names.dat</span>
MEAN_X
MEAN_X_SQUARED
MEAN_ENERGY
</pre>

<p>We are now ready to run the first Distribution Sampling
utility, <code>madai_generate_training_points</code>.  This program
will generate a Latin hypercube in the parameter space.  The number of
sample points is set by
the <code>GENERATE_TRAINING_POINTS_NUMBER_OF_POINTS</code>
variable. (The command-line argument is the name of the working
directory.)</p>
<pre>
$ <span class="input">madai_generate_training_points .</span>
</pre>

<p>The output of <code>generateTrainingPoints</code> is a series of
files <code>model_output/run*/parameters.dat</code>.  For example:</p>

<pre>$ <span class="input">cat ./model_output/run0001/parameters.dat</span>
X0 0.94
K 2.3025
TEMP 5.0125</pre>

<p>The next task is to actually evaluate the model at this point in
parameter space.  We have written a little Python program to do just
that.</p>

<pre>$ <span class="input">../parabolic_example/parabolic_evaluate.py model_output/run*</span></pre>

<p><code>parabolic_evaluate.py</code> takes as command-line arguments
the names of a directory that contains a
file <code>parameters.dat</code> and write a file
called <code>results.dat</code>.</p>

Verify that it works

<pre>$ <span class="input">cat ./model_output/run0001/results.dat</span>
MEAN_X 0.94 1.04330761087
MEAN_X_SQUARED 1.9720907709 2.49334837063
MEAN_ENERGY 5.0125 3.5443727407</pre>

<div class="box">
<p><em>Aside:</em> It doesn't matter how you populate
the <code>results.dat</code> files.  We expect that you may be running
the full model on a supercomputer or on a dozen nodes of a
cluster.</p> <p>Also, the <code>parameters.dat</code> files don't have
to be a Latin hypercube.  You are free to select them using any
method.</p></div>

<p>After generating the training points, we generate the principal
component analysis decomposition of the outputs.</p>
<pre>$ <span class="input">madai_pca_decompose .</span></pre>

<p>The file <code>pca_decomposition.dat</code> contains the PCA
data. The eigenvalues are sorted in increasing order.</p>

<p>The next step is to generate a Gaussian Process Emulator on the
training points.  The hyper-parameters of the emulator are the
hyper-parameters of the covariance (kernel) functions on the parameter
space and the regression function.  The <code>madai_train_emulator</code>
program generates &ldquo;okay&rdquo; values for the
hyper-parameters.</p>

<div class="box">
<p><em>Aside:</em> The default covariance function is a square
exponential function:</p>

<p class="centered">dist(<em>u</em>,<em>v</em>) = sqrt(sum(
((<em>u</em>[<em>i</em>]-<em>v</em>[<em>i</em>]) /
&theta;[<em>i</em>+2])^<sup>2</sup> ))</p>
<p class="centered">Cov(<em>u</em>,<em>v</em>) = &theta;[0] exp(
(-0.5) dist(<em>u</em>,<em>v</em>)^<sup>2</sup>) + &theta;[1]
&delta;[<em>u</em>,<em>v</em>]</p>

<p>Where <em>u</em> and <em>v</em> are points in parameter space,
&theta; is a list of hyper-parameters and &delta; is the Kronecker
delta.</p>

<p>By default, the nugget (&theta;[1]) is <code>EMULATOR_NUGGET</code>
and the amplitude (&theta;[0]) is <code>EMULATOR_AMPLITUDE</code>. We
define the characteristic length scale of a parameter value as the
difference between the 75th percentile and the 25th percentile of the
prior distribution.  For a uniform prior, this is half the range.  The
default value for &theta;[2+<em>i</em>] the characteristic length
scale of the <em>i</em>th parameter times
the <code>EMULATOR_SCALE</code> option.</p>

<p>For more information, see the manual.</p>
</div>

<p>To run the basic training program:</p>

<pre>
$ <span class="input">madai_train_emulator .</span>
</pre>

<p><code>madai_train_emulator</code> writes out a
file <code>emulator_state.dat</code> which contains hyper-parameters
for each of the retained pca-decomposed sub-models.

<p>The final step is to run the Markov chain Monte Carlo (MCMC)
routine on the code.  The <code>madai_generate_trace</code>
program uses the trained Gaussian Process model emulator to produce
model outputs for points in parameter space.  These model outputs are
compared to observed values to calculate likelihood.</p>

<p class="centered"><em>L</em> &#8733; exp((-0.5) sum(
((<em>Y<sub>_observed</sub></em>[<em>i</em>] - <em>Y<sub>_model</sub></em>[<em>i</em>]) /
&sigma;[<em>i</em>] ))^<sup>2</sup>)</p>

<p>The Metropolis-Hastings MCMC algorithm is used to draw a large
number of samples from the distribution proportional to likelihood.
These values are stored in a comma-separated-value (csv) file
specified in the arguments.</p>

<pre>
$ <span class="input">madai_generate_trace . &quot;mcmc.csv&quot;</span>
</pre>

<p>The output file is left in the <code>trace</code> directory:</p>

<pre>
$ <span class="input">head trace/mcmc.csv</span>
&quot;X0&quot;,&quot;K&quot;,&quot;TEMP&quot;,&quot;MEAN_X&quot;,&quot;MEAN_X_SQUARED&quot;,&quot;MEAN_ENERGY&quot;,&quot;LogLikelihood&quot;
-0.167188,1.63734,0.790651,0,0,0,-7.0052
-0.176625,1.60696,0.673026,-0.176625,1.87896,0.673026,-6.89768
-0.181315,1.61748,0.744548,-0.181315,1.89524,0.744548,-6.97992
-0.181315,1.61748,0.744548,-0.181315,1.89524,0.744548,-6.97992
-0.222542,1.62965,0.668291,-0.222542,1.85553,0.668291,-6.85991
-0.188486,1.62792,0.638246,-0.188486,1.84436,0.638246,-6.81262
-0.198998,1.65095,0.659951,-0.198998,1.82891,0.659951,-6.80038
-0.19968,1.6921,0.574281,-0.19968,1.75331,0.574281,-6.61224
-0.19968,1.6921,0.574281,-0.19968,1.75331,0.574281,-6.61224
</pre>

<p>The <code>madai_generate_trace</code> program will produce the
number of points specified in the <code>settings.dat</code> under in
the <code>SAMPLER_NUMBER_OF_SAMPLES</code> variable.  Depending on the
number of the parameters, a larger or smaller number of samples will
need to be drawn.  Once you are sure that the program is working
correctly, set <code>SAMPLER_NUMBER_OF_SAMPLES</code> to a large number
(a million or more) and let the program run for a while.</p>

<pre>
$ <span class="input">madai_set_variable . SAMPLER_NUMBER_OF_SAMPLES 1000000</span>
old: SAMPLER_NUMBER_OF_SAMPLES 100
new: SAMPLER_NUMBER_OF_SAMPLES 1000000
$ <span class="input">madai_set_variable . MCMC_NUMBER_OF_BURN_IN_SAMPLES 200</span>
old: MCMC_NUMBER_OF_BURN_IN_SAMPLES 0
new: MCMC_NUMBER_OF_BURN_IN_SAMPLES 200
$ <span class="input">madai_generate_trace . &quot;million.csv&quot;</span>
</pre>

<h3 id="Downsampling">Downsampling</h3>

<p>While visualization software is capable of displaying ten million
points in space, for analysis you may need to reduce the number of
points.  To keep the same random distribution, it may be easiest to
pick out every <em>N</em>th line.  For example, to reduce one million
points down to a fifty thousand, pick out every 20th line:</p>

<pre>
$ <span class="input">madai_subsample_text_file 20 trace/million.csv trace/mcmc_50000.csv</span>
</pre>

<h3 id="BasicStatistics">Basic Statistics</h3>

<pre>
$ <span class="input">madai_analyze_trace . million.csv</span>
     parameter       average      std.dev.   scaled dev.    best value
            X0   -0.00379224      0.925268      0.801305     0.0170338
             K       2.82017       0.86125      0.852416       3.98649
          TEMP       1.84148       1.08205      0.394561      0.500879

covariance:
                          X0             K          TEMP
            X0       0.85612    0.00873217     0.0299062
             K    0.00873217      0.741751     0.0384384
          TEMP     0.0299062     0.0384384       1.17083

scaled covariance:
                          X0             K          TEMP
            X0       0.64209    0.00748472    0.00944407
             K    0.00748472      0.726613     0.0138725
          TEMP    0.00944407     0.0138725      0.155678
</pre>

<h2 id="Visualizing">3. Visualizing the Results</h2>

<p>TO BE FIXED BEFORE THE TUTORIAL</p>

<!-- <h3>3a. ParaView</h3> -->
<!-- <p>CSV files can be opened in ParaView or the MADAI Workbench.</p> -->

<p><a href="images/screenshot_001.png">
<img src="images/screenshot_001.png" alt="" width="218" height="209"></a>
<a href="images/screenshot_002.png">
<img src="images/screenshot_002.png" alt="" width="218" height="209"></a>
<a href="images/scatterplot.png"><img src="images/scatterplot.png" alt="" width="218" height="189"></a>
<a href="images/screenshot_003.png"><img src="images/screenshot_003.png" alt="" width="218" height="187"></a>
<a href="images/screenshot_004.png"><img src="images/screenshot_004.png" alt="" width="178" height="141"></a></p>

<!-- <h3>3b. Scatterplot Matrix</h3> -->

<!-- <p>This image was created via <a href="http://matplotlib.org/">Matplotlib</a>.</p> -->

<!-- <h3>3c. GGobi</h3> -->
<!-- <p>CSV files can be directly loaded by GGobi.</p> -->

<!-- <h3>3d. Percentile Surface</h3> -->
<!-- <p>This is a stand-alone program that links against VTK. Compiling -->
<!--   instructions are located inside the file.</p> -->
<!-- <p><a href="/~hal/pub/PercentileSurface.tgz">PercentileSurface.tgz</a></p> -->
<!-- <p>This is the 95% surface</p> -->
<!-- <p><img src="images/screenshot_003.png" alt=""></p> -->
<!-- <p>This is a comparison of the the 95% surface to a scatterplot of the -->
<!-- samples.</p> -->
<!-- <p><img src="images/screenshot_004.png" alt=""></p> -->

<hr>

</div>
</body>
</html>

<!--  LocalWords:  px pre moz dddddd MaxOS RedHat Eigen sudo cmake cd
      LocalWords:  libboost dev libeigen groupinstall devel eigen src
      LocalWords:  MacOS macports mkdir executables EOF PCA py mcmc
      LocalWords:  csv utf os sys Wyka xrange elif sqrt
      LocalWords:  GetGaussianIntegral MeanX MeanE ErrorX ErrorE dat
      LocalWords:  rundir params IOError len argv arg tt ffffff th td
      LocalWords:  DistributionSampling cbracket preproc specialchar
      LocalWords:  madai_generate_trace stdout endin
      LocalWords:  STDDEV ParabolicPotentialModel stdin LogLikelihood
      LocalWords:  pca Cov awk ln MyModel cxx iostream fstream madai
      LocalWords:  ErrorType GetScalarOutputsAndCovariance const cerr
      LocalWords:  GetScalarOutputs AddParameter AddScalarOutputName
      LocalWords:  SetObservedScalarValues outputCovariance ofstream
      LocalWords:  SetObservedScalarCovariance SetStepSize Makefile
      LocalWords:  MetropolisHastingsSampler SamplerCSVWriter Wextra
      LocalWords:  GenerateSamplesAndSaveToFile CXXFLAGS LDFLAGS
      LocalWords:  lDistributionSampling subsample whitespace
 -->
