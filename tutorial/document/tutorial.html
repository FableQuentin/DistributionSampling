<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<title>MADAI Distribution Sampling Tutorial</title>
<style>
div.column { color:black; background-color:white; margin-left:auto;
	margin-right:auto; margin-top:0px; margin-bottom:0px;
	max-width:872px; text-align:left; padding:8px 8px 8px 8px;
	border:1px solid #56A0D3; }
div.box { margin: 16px 2em;; border:2px solid #56A0D3;
		padding:0 0.5ex;  }
div.box p { margin: 0px 0; padding: 8px 0; }
div.figure { margin: 16px 2em;; border:2px solid #56A0D3;
		padding:0 0.5ex; text-align:justified;  }
div.figure p { margin: 8px 8px; }
div.wide { color:black; background-color:white; margin-left:0.5em;
	margin-right:0.5em; padding:0.5em; }
body { color:#000000; background-color:#56A0D3; padding:0; margin:0;
	font-family:sans-serif; text-align:center; background-repeat:
	repeat; background-attachment:fixed; background-size:cover; }
code { color:#001A57;background-color:#ffffff;}
pre .input { color:#001A57; background-color:#f0f0f0; }
pre { color:#333300; background-color:#f0f0f0;
	overflow:auto; overflow-y:visible;
	border-left:2px #dddddd solid; margin-left:15px;
	padding-left:10px; padding-top:2px; padding-bottom:2px;
	margin-top:3px; margin-bottom:3px; z-index:12; }
table { border-collapse:collapse; }
th { color:black; background-color:#f0f0f0;}
td,th { border:1px black solid; text-align:left}
hr { width:100%; background-color:#56A0D3; color:#001A57;
	border:0;height:1px; margin:0}
.centered {text-align:center;}
.cbracket { color:#440044; background-color:#f0f0f0;
	text-decoration:none; font-weight:bold; }
.comment { color:#880000; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.function { color:#008800; background-color:#f0f0f0;
	text-decoration:none; font-weight:bold; }
.keyword { color:#000088; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.normal { color:#000000; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.number { color:#224466; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.preproc { color:#444400; background-color:#f0f0f0;
	text-decoration:underline; font-weight:normal; }
.specialchar { color:#004488; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.string { color:#004444; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.symbol { color:#008844; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.type { color:#444444; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
</style>
<script>
function toggleViz(name) {
  var e = document.getElementById(name);
  if(e.style.display == 'block') {
    e.style.display = 'none';
  } else {
    e.style.display = 'block';
  }
  return false;
}
</script>
</head>
<body>
<div class="column">
<!--=========================================================================-->
<h1>MADAI Distribution Sampling Tutorial</h1>

<hr/>
<p><strong>Authors:</strong> Hal Canary and Cory Quammen</p>

<hr/>
<p><strong>Contents</strong></p>
<ul style="list-style-type:none;">
<li>0. <a href="#Introduction">Introduction</a></li>
    <ul style="list-style-type:none;">
      <li>a. <a href="#notation">Tutorial Notation</a></li>
    </ul>
<li>1. <a href="#Installing">Installing Software</a></li>
		<ul style="list-style-type:none;">

		<li>a. <a href="#DST">The Distribution Sampling Tools</a></li>
    <li>b. <a href="#MADAIWorkbench">MADAI Workbench</a></li>
		<!-- <li>c. <a href="#other">Other software</a></li> -->
		</ul>
<li>2. <a href="#Running">Running the Software </a></li>
		<ul style="list-style-type:none;">
		<li>a. <a href="#Fast">Markov chain Monte Carlo with a Fast
 			Model</a></li>
		<li>b. <a href="#BasicStatistics">Basic Statistics</a></li>
		<li>c. <a href="#Downsampling">Downsampling</a></li>
		<li>d. <a href="#Plotting">Plotting</a></li>

		<li>e. <a href="#Slow">Use an Emulator for a Slow Model</a></li>
		</ul>
<li>3. <a href="#Visualizing">Visualizing the Results</a></li>
		<ul style="list-style-type:none;">
		<li>a. <a href="#Slices">Visualizing a Slice of Parameter Space</a></li>
		<li>b. <a href="#PercentileSurfaceFilter">Percentile Surface Filter</a></li>
		</ul>

</ul>

<hr/>

<!--=========================================================================-->
<h2 id="Introduction">0. Introduction</h2>

<p>The MADAI Distribution Sampling tools enable you to estimate the
most likely parameters of a model and the surrounding probability
density by comparing the output from the model at a given set of
parameters to a set of values obtained through actual experiment. The
tools are intended to help answer which parameters of a model of a
system best explain aspects of the system being modeled.</p>

<p>This tutorial will introduce you to the MADAI Distribution Sampling
tools. It will walk you through generating a probability distribution
of an example model in two different ways, computing information about
the samples in the distribution, and visualizating the
distribution. The tutorial is designed to be read from start to
finish.</p>

<h3 id="notation">0a. Tutorial Notation</h3>

<p>Throughout the document, some special notation is used</p>

<ul>

  <li>
    <p>This indicates that you should enter the
    command <code>command</code> at the terminal:</p>
    <pre>
$ <span class="input">command</span></pre>
  </li>
  <li>
    <p>This indicates output produced by a program:</p>
    <pre>output</pre>
  </li>
  <li>
    <div class="box">
    <p><em>Aside:</em> Indicates additional information that is not
    critical to completing the tutorial but which may be useful to
    know. You may opt to skip these sections and come back to them
    later.</p>
    </div>
  </li>

</ul>

<!-- <p><img src="images/MADAI_Stats_and_Vis2.png" alt=""></p> -->

<!-- \todo insert background for what we want to accomplish -->

<!--=========================================================================-->
<h2 id="Installing">1. Installing Software</h2>

<h3 id="DST">1a. The Distribution Sampling Tools</h3>

<ol>
  <li>Install the prerequisite packages
  (<a href="http://www.cmake.org/cmake/resources/software.html">CMake</a>,
  <a href="http://www.boost.org/users/download/">Boost</a>,
  <a href="http://eigen.tuxfamily.org/">Eigen3</a>):
	<ul>
	  <li>Ubuntu/Debian-based:
		<pre>
$ <span class="input">sudo apt-get -y install build-essential</span>
$ <span class="input">sudo apt-get -y install cmake libboost-dev libeigen3-dev gnuplot</span></pre>
	  </li>
	  <li>Red Hat-based:
<pre>
$ <span class="input">sudo yum -y groupinstall "Development Tools"</span>
$ <span class="input">sudo yum -y install cmake boost-devel eigen3-devel gnuplot</span></pre>
	  </li>
	  <li>MacOS 10.x with macports:
	    <pre>$ <span class="input">sudo port install cmake boost eigen3 gnuplot</span></pre>
	  </li>
	</ul>
  </li>
  <li>Download the file <code>DistributionSampling-VERSION.tgz</code> from <a href="https://madai-public.cs.unc.edu/statistical-tools/distribution-sampling-library/">the MADAI web site</a>.</li>
  <li>Navigate to the directory where you downloaded the Distribution
  Sampling tools.</li>
  <li>Extract the tools archive.

<pre>
$ <span class="input">tar -x -z -f DistributionSampling.tar.gz</span></pre></li>
  <li>Build and install.  In this example, we will install in <code>${HOME}/local</code>.
<pre>
$ <span class="input">cd DistributionSampling</span>
$ <span class="input">build.sh "${HOME}/local"</span></pre>
  </li>
</ol>

<div class="box">
<p><em>Aside:</em> MacOS 10.x users who do not have macports and need Boost or Eigen3 can still install this library.  You must get CMake
from <a href="http://www.cmake.org/cmake/resources/software.html#latest">www.cmake.org</a>. Then run the command:</p>
<pre>
$ <span class="input">full_build.sh "${HOME}/local"</span></pre>
<p>This will download the necessary Boost and Eigen3 headers into a temporary directory for the compilation. </p>
</div>

<div class="box">
<p><em>Aside:</em> The <code>build.sh</code>
and <code>full_build.sh</code> scripts simply call CMake.  You can
also run CMake directly.</p>
<pre>
$ <span class="input">cd ..</span>
$ <span class="input">mkdir build</span>
$ <span class="input">cd build</span>
$ <span class="input">cmake "../DistributionSampling" \
    -DCMAKE_INSTALL_PREFIX:PATH="${HOME}/local" \
    -DBoost_INCLUDE_DIR:PATH="/usr/include" \
    -DEIGEN3_INCLUDE_DIR:PATH="/usr/include/eigen3" \
    -DCMAKE_BUILD_TYPE:STRING=Release \
    -DBUILD_TESTING:BOOL=0 \
    -DUSE_OPENMP:BOOL=0 \
    -DUSE_GPROF:BOOL=0</span>
$ <span class="input">make</span>
$ <span class="input">make install</span>
$ <span class="input">PATH=&quot;${PATH}:${HOME}/local/bin&quot;</span>
$ <span class="input">cd ../DistributionSampling</span>
</pre></div>

<p>Your executables will be in the
directory <code>${HOME}/local/bin</code>. You should
make these executables available by including this directory in your
path. If you use bash, write</p>
<pre>$ <span class="input">PATH=&quot;${PATH}:${HOME}/local/bin&quot;</span></pre>

<p>If you have csh/tcsh as your shell, write:</p>
<pre>
$ <span class="input">set path = ($path &quot;${HOME}/local/bin&quot;)</span></pre>

<p>If you do not know your shell type, write:</p>
<pre>
$ <span class="input">echo $SHELL</span></pre>

<div class="box">
<p><em>Aside:</em> If you wish to compile your own software that links against the library, the include files are in <code>${HOME}/local/include</code> and the library is in <code>${HOME}/local/lib/madai</code> . </p></div>

<h3 id="MADAIWorkbench">1b. MADAI Workbench</h3>

<p>The <a href="http://vis.madai.us">MADAI Workbench</a> version 1.8
or higher is required for Section 3 of the tutorial. The MADAI
Workbench is a customized version of ParaView with additional filters
that support visualization of high dimensional data.</p>

<!--

<h3 id="other">1c. Other software</h3>

<p>This additional software may be useful to you, but is not necessary for the tutorial.</p>

<ul>

  <li>ParaView &mdash; <a href="http://www.paraview.org/paraview/resources/software.php">paraview.org</a>
    <pre>$ <span class="input">sudo apt-get -y install paraview</span></pre>
    <pre>$ <span class="input">sudo yum -y install paraview</span></pre>
  </li>

  <li>GGobi &mdash; <a href="http://www.ggobi.org/downloads/">ggobi.org</a>
    <pre>$ <span class="input">sudo apt-get -y install ggobi</span></pre>
    <pre>$ <span class="input">sudo yum -y install ggobi</span></pre>
  </li>

</ul>

-->

<!--=========================================================================-->
<h2 id="Running">2. Running the Software</h2>
<h3 id="Fast">2a. Markov Chain Monte Carlo with a Fast Model</h3>

<p>This section describes how to perform Markov Chain Monte Carlo
sampling with a "fast model". By a "fast model" we mean that it can
execute millions of times in the time it takes to get a cup of
coffee.</p>

<p>To invoke such a model from the MADAI Distribution Tools, you will
need to build an executable program to interface with
the <code>madai_generate_trace</code> program. Your program will write
information about the model to <code>stdout</code>, read parameter
values from <code>stdin</code>, and write model outputs
to <code>stdout</code>. <code>madai_generate_trace</code> will start
your program and interactively query it for model outputs at given
parameter vectors.</p>

<p>In this example, we have written a program that models a parabolic
potential. In this case, the program,
named <code>parabolic_interactive.py</code>, is written in Python. It
is located in the
directory <code>DistributionSampling/tutorial/parabolic_example/</code></p>

 This model has the
parameters <code>X0</code>, <code>K</code>, and <code>TEMP</code>; and
the observables <code>MEAN_X</code>, <code>MEAN_X_SQUARED</code>, and
<code>MEAN_ENERGY</code>. When we run the program, the output looks
like:</p>

<pre>
$ <span class="input">cd tutorial</span>
$ <span class="input">python parabolic_example/parabolic_interactive.py</span>
# ParabolicPotentialModel
VERSION 1
PARAMETERS 3
X0	UNIFORM	-2.0	2.0
Kinv	UNIFORM	0.25	4.0
TEMP	UNIFORM	0.25	4.0
OUTPUTS 3
MEAN_X
MEAN_X_SQUARED
MEAN_ENERGY
VARIANCE 3
END_OF_HEADER
<span class="input">STOP</span></pre>

<ul>

  <li><p>Line 1 (# ParabolicPotentialModel) is a comment. In this
      case, it reports the name of the model.</p></li>

  <li><p>Line 2 (VERSION 1) indicates the version of the input/output
      format the Distribution Sampling tools use to interface with
      external programs.</p></li>

  <li><p>Line 3 (PARAMETERS 3) begins the parameters description
      section and indicates how many parameters are in the
      model.</p></li>

  <li><p>Lines 4-6 describe the parameters. The first item is the
      parameter name, the second item is the type of prior
      distribution for the parameter, the third and fourth items
      indicate the minimum and maximum values where the uniform
      distribution is non-zero.</p></li>

  <li><p>Line 7 (OUTPUTS 3) begins the output description
  section.</p></li>

  <li><p>Lines 8-10 gives the output parameter names.</p></li>

  <li><p>Line 11 (VARIANCE 3) gives the form of the model output
  covariance.</p></li>

  <li><p>Line 12 (END_OF_HEADER) indicates that the header describing
  the model inputs and outputs has ended.</p></li>

</ul>

<p>The external model then waits for a list of parameter values
(encoded as text) on stdin.  Then it returns the model outputs
followed by the model covariances.  For example, if you type the first
line shown below, you will get the output values from the model (the
second line) and the output variances (the third line):

<pre>
<span class="input">0 2.25 2.25</span>
1.7952402618064471 5.0625 2.25
0.1125 0.6570540589064506 0.25851201309032235
</pre>

<div class="box">
  <p><em>Aside:</em> The Interactive Model Language.</p>
  <ol>
    <li>First the <strong>external model</strong> (your program) will
      output on standard output (stdout) a list of comments (each
      beginning with a '#' and ending with a '\n').</li>

    <li>Then it will output the string &quot;VERSION 1 \n&quot;</li>

    <li>Then it will output the string &quot;PARAMETERS <em>Nparam</em>
      \n&quot;, where <em>Nparam</em> is the number of parameters.</li>

    <li>Then, for each parameter, it will output the name of the
      parameter (a string without whitespace), whitespace, the prior
      distribution, and '\n'

      <ul>

	<li>A uniform prior distribution is in the format &quot;UNIFORM <em>MIN</em> <em>MAX</em>&quot;</li>

	<li>A Gaussian prior distribution is in the format &quot;GAUSSIAN <em>MEAN</em> <em>STDDEV</em>&quot;</li>

      </ul>

    </li>

    <li>Then the string &quot;OUTPUTS <em>Nouts</em> \n&quot;, where <em>Nouts</em> is the number of outputs.</li>

    <li>Then, for each parameter, it will output the name of the output (a string without whitespace), followed by a '\n'</li>

    <li>Then it either outputs:

      <ul>

	<li>&quot;VARIANCE <em>Nouts</em> \n&quot; (<em>Nouts</em> is still the number of outputs), <br>or</li>

	<li>&quot;COVARIANCE TRIANGULAR_MATRIX <em>M</em> \n&quot;, where <em>M</em>=<em>Nouts</em>&times;(<em>Nouts</em>+1)/2)<br>or</li>

	<li>&quot;COVARIANCE FULL_MATRIX <em>K</em> \n&quot;, where <em>K</em>=<em>Nouts</em>^<sup>2</sup></li>

      </ul>

    </li>

    <li>The external model them prints &quot;END_OF_HEADER \n&quot; </li>

    <li>The external model will then wait for <em>Nparam</em> ASCII-encode floating-point numbers on standard input.  These will be interpreted as a set of parameter values.</li>

    <li>The external model should calculate model outputs at that point in parameter space, as well as (co)variance.  It will then print those numbers (ASCII-encoded) onto standard output.  Remember to flush standard out after writing.</li>

    <li>The external model should then wait for the next set of parameters and repeat the output calculation</li>

    <li>The external model should exit when it reads the string &quot;STOP&quot; or end-of-file or received an interrupt signal.</li>
  </ol>
</div>

<p>To create a distribution sampling from the example model, first make sure you are in the <code>DistributionSampling/tutorial</code> directory.</p>

<p>Then make a working directory:</p>
<pre>
$ <span class="input">mkdir parabolic_fast</span>
$ <span class="input">cd parabolic_fast</span></pre>

<p>For the rest of this section, we will assume that you are in your
working directory and will refer to it as <code>.</code> (a single
dot).)</p>

<p>Next, copy the “experimental” results file into the working directory.  This specifies all of the experimentally observed measurements and errors. (If you skip that step, it assumes that the measurements are 0.0 and the error is 1.0.)
</p>
<pre>$ <span class="input">cp ../parabolic_example/experimental_results.dat .</span>
$ <span class="input">cat experimental_results.dat</span>
MEAN_X         1.28759997   0.050
MEAN_X_SQUARED 2.28759997   0.179
MEAN_ENERGY    0.856200015  0.139
</pre>

<p>Next, we  will create a <code>settings.dat</code> file in
  this directory with some default values in it. All of the
  Distribution Sampling tools will look for this file.</p>
<pre>$ <span class="input">madai_print_default_settings &gt; ./settings.dat</span></pre>

<div class="box">
<p><em>Aside:</em> <code>madai_print_default_settings</code> produces
numerous settings. A detailed description of the options
in <code>settings.dat</code> can be found in the MADAI Statistics
Manual.</p></div>

<p>Now, use you favorite text editor to edit
the <code>settings.dat</code> file. Change the setting
EXTERNAL_MODEL_EXECUTABLE to
<code>../parabolic_example/parabolic_interactive.py</code>.
Alternatively, use the <code>madai_change_setting</code> program to
change the setting:
</p>

<pre>
$ <span class="input">madai_change_setting . EXTERNAL_MODEL_EXECUTABLE \
    &quot;../parabolic_example/parabolic_interactive.py&quot;</span></pre>

<p>The final step is to run the Markov chain Monte Carlo (MCMC)
routine on your model.  The <code>madai_generate_trace</code> program
uses the external model to produce model outputs for points in
parameter space.  These model outputs are compared to the experimental
values to calculate likelihood.</p>

<p>The Metropolis-Hastings MCMC algorithm is used to draw a large
number of samples from the distribution proportional to likelihood.
These values are stored in a comma-separated-value (CSV) file
specified in the arguments.</p>

<pre>
$ <span class="input">madai_generate_trace . &quot;mcmc.csv&quot;</span>
</pre>

<p>We use the term "trace" to refer to the samples generated from the
MCMC algorithm.</p>

<pre>
$ <span class="input">head mcmc.csv</span>
&quot;X0&quot;,&quot;Kinv&quot;,&quot;TEMP&quot;,&quot;MEAN_X&quot;,&quot;MEAN_X_SQUARED&quot;,&quot;MEAN_ENERGY&quot;,&quot;LogLikelihood&quot;
0.753519,1.57836,0.899513,1.28201,2.38578,0.77336,-4.36406
0.753519,1.57836,0.899513,1.28201,2.38578,0.77336,-4.36406
0.746218,1.66737,0.818389,1.26077,2.30536,0.703248,-4.78413
0.767981,1.59083,0.805214,1.24539,2.2374,0.689978,-5.1405
0.772022,1.54362,0.861303,1.26323,2.30477,0.738468,-4.5119
0.772022,1.54362,0.861303,1.26323,2.30477,0.738468,-4.5119
0.772022,1.54362,0.861303,1.26323,2.30477,0.738468,-4.5119
0.695059,1.4549,0.863633,1.19886,2.08978,0.743292,-6.54539
0.695059,1.4549,0.863633,1.19886,2.08978,0.743292,-6.54539
</pre>

<p>The <code>madai_generate_trace</code> program will produce the
number of points specified in the <code>settings.dat</code> under
the <code>SAMPLER_NUMBER_OF_SAMPLES</code> setting.  The more
parameters a model has, the larger the number of samples that will
need to be drawn to fill the parameter space.  Once you are sure that
the program is working correctly,
set <code>SAMPLER_NUMBER_OF_SAMPLES</code> to a large number (e.g.,
one million) and let the program run for a while.</p>

<pre>
$ <span class="input">madai_change_setting . SAMPLER_NUMBER_OF_SAMPLES 1000000</span>
old: SAMPLER_NUMBER_OF_SAMPLES 100
new: SAMPLER_NUMBER_OF_SAMPLES 1000000
</pre>

<p>
It is not unusual for the MCMC algorithm to start in a region of low
likelihood. The result is that some of the first samples in the
generated trace appear to stick out from the main regions of high
likelihood in the distribution. We refer to this phase of the MCMC
evolution as the &quot;burn-in&quot; phase. To remove these samples, you can
specify a setting called <code>MCMC_NUMBER_OF_BURN_IN_SAMPLES</code>
that discards the first <em>N</em> samples.
</p>

<pre>
$ <span class="input">madai_change_setting . MCMC_NUMBER_OF_BURN_IN_SAMPLES 200</span>
old: MCMC_NUMBER_OF_BURN_IN_SAMPLES 0
new: MCMC_NUMBER_OF_BURN_IN_SAMPLES 200
$ <span class="input">madai_generate_trace . &quot;million.csv&quot;</span>
</pre>

<p>Here, we discard 200 samples from the trace generated by the MCMC
algorithm. Note that the number of burn-in samples are not subtracted
from the number of samples specified
by <code>SAMPLER_NUMBER_OF_SAMPLES</code>.</p>

<h3 id="BasicStatistics">2b. Basic Statistics</h3>

<p>The utility <code>madai_analyze_trace</code> computes some basic
statistics about the samples in the generated trace that may be useful
to know. Example output from this program is shown below.</p>

<pre>
$ <span class="input">madai_analyze_trace . million.csv</span>
     parameter          mean      std.dev.   scaled dev.    best value
            X0      0.644224      0.475285      0.411609      0.999923
          Kinv       1.68241      0.903106      0.834254       1.00104
          TEMP      0.929729      0.158476      0.146394      0.998231

best log likelihood
       -4.0299

covariance:
                          X0          Kinv          TEMP
            X0      0.225896     -0.401274      0.014398
          Kinv     -0.401274        0.8156    -0.0649426
          TEMP      0.014398    -0.0649426     0.0251147

scaled covariance:
                          X0          Kinv          TEMP
            X0      0.169422     -0.321019     0.0115184
          Kinv     -0.321019      0.695979    -0.0554177
          TEMP     0.0115184    -0.0554177     0.0214312
</pre>

<h3 id="Downsampling">2c. Downsampling</h3>

<p>While visualization and analysis software is capable of handling
tens of millions of points, for faster visualization and analysis you
may need to reduce the number of points. One way to keep the same
random distribution is to pick out every <em>N</em>-th line.  For
example, to reduce one million points down to a fifty thousand, pick
out every 20th line:</p>

<pre>
$ <span class="input">madai_subsample_text_file 20 million.csv mcmc_50000.csv</span>
</pre>

<p>The <code>madai_subsample_text_file</code> program will sample
every <em>N</em>-th sample point from a CSV file into a new CSV file.</p>

<pre>$ <span class="input">madai_subsample_text_file 20 mcmc.csv mcmc_50000.csv</span></pre>

<div class="box">
<p><em>Aside:</em> A faster way to interface with the Distribution
Sampling tools is to link directly to the Distribution Sampling
library. For a complete example, look in
the <code>DistributionSampling/tutorial/examples/ParabolicPotentialModelCxx</code>
directory.</p>

<p>A skeleton for your own C++ model can be found
in <code>DistributionSampling/tutorial/examples/MCMC_Example</code> .
</div>

<h3 id="Plotting">2d. Plotting</h3>

<p>Now that the distribution samples have been computed, it is useful
to visualize the distribution. One way to do this is to create a
scatterplot matrix that shows pair-wise scatterplots of the parameter
values. We first need to create a file listing the names of the
parameters. We will borrow a file used in the next section to do this:
</p>

<pre>
$ <span class="input">cp ../parabolic_example/parameter_priors.dat .</span></pre>

<p>This file lists the property names and some other information. Next, generate the scatterplot matrix with</p>

<pre>
$ <span class="input">madai_gnuplot_scatterplot_matrix mcmc.csv mcmc.pdf parameter_priors.dat 50</span></pre>

<p>You will see the plot shown in Figure 1.</p>

<div class="figure">
  <div class="centered">
    <a href="images/mcmc_fast_50000.png"><img src="images/mcmc_fast_50000.png" width="75%" height="75%"/></a>
  </div>
  <div>
    <p>Figure 1: Scatterplot matrix of the trace data. The horizontal
      axis is labeled with the input parameter names. The left vertical axis
      also lists the input parameter names except for the first row which is
      labeled "likelihood". Each plot in the matrix, which the exception of
      plots on the diagonal, is the scatterplot of the parameter by which it
      is labeled in the horizontal axis and the parameter by which it is
      labeled in the vertical axis. The plots in the upper right of the
      matrix are redundant with the plots in the lower left. Each plot on
      the diagonal is a histogram that shows the density of the sample
      points in each dimension.</p>
  </div>
</div>

<!--=========================================================================-->
<h3 id="Slow">2e. Use an Emulator for a Slow Model</h3>

<p>The Distribution Sampling tools use a Gaussian Process Emulator to
emulate a slow model much more quickly than if the model were run
directly. An emulator is basically an interpolator that can estimate
the uncertainty associated with the outputs it produces.  To train the
emulator, the software requires hundreds of sample points.  At each
training point, you will need the parameter values and the model
outputs.</p>

<p>We will use the parabolic potential model as an example again.
This model has the parameters <code>X0</code>, <code>Kinv</code>,
and <code>TEMP</code>; and the observables <code>MEAN_X</code>,
<code>MEAN_X_SQUARED</code>, and <code>MEAN_ENERGY</code>.</p>

<p>First move into the <code>DistributionSampling/tutorial</code> directory.</p>

<p>Then make a working directory:</p>
<pre>
$ <span class="input">mkdir -p parabolic_emulator</span>
$ <span class="input">cd parabolic_emulator</span></pre>

<p>For the rest of this section, we will assume that you are in your
working directory and will refer to it as <code>.</code> (a single
dot).)</p>

<p>The first thing we will do is create a <code>setting.dat</code>
file in this directory with some default values in it. All of the
Distribution Sampling tools will look for this file.</p>

<pre>$ <span class="input">madai_print_default_settings &gt; ./settings.dat</span></pre>

<p>Next, we need to create a parameter_priors.dat file that contains
our assumptions about prior probability distribution for the values
for the parameters.

<pre>$ <span class="input">cp ../parabolic_example/parameter_priors.dat .</span>
$ <span class="input">cat parameter_priors.dat</span>
UNIFORM X0      -2.0    2.0
UNIFORM Kinv    0.25    4.0
UNIFORM TEMP    0.25    4.0
</pre>

<p>Next, we specify all of the experimentally observed
measurements and errors:</p>

<pre>$ <span class="input">cp ../parabolic_example/experimental_results.dat .</span>
$ <span class="input">cat experimental_results.dat</span>
MEAN_X         1.28759997   0.050
MEAN_X_SQUARED 2.28759997   0.179
MEAN_ENERGY    0.856200015  0.139
</pre>

<p>Finally, we create a file that contains the list of observables
that we want to make use of.  This should be a subset
of <code>results.dat</code>.</p>

<pre>$ <span class="input">cp ../parabolic_example/observable_names.dat .</span>
$ <span class="input">cat observable_names.dat</span>
MEAN_X
MEAN_X_SQUARED
MEAN_ENERGY
</pre>

<p>We are now ready to run the first Distribution Sampling tool in
this workflow, <code>madai_generate_training_points</code>.  This
program will generate a Latin hypercube in the parameter space.  The
number of sample points is determined by
the <code>GENERATE_TRAINING_POINTS_NUMBER_OF_POINTS</code>
setting. Like the other Distribution Sampling tools, the command-line
argument is the name of the working directory.</p>
<pre>
$ <span class="input">madai_generate_training_points .</span>
</pre>

<p>The output of <code>madai_generate_training_points</code> is a series of
files <code>model_output/run*/parameters.dat</code>.  For example:</p>

<pre>$ <span class="input">cat ./model_output/run0001/parameters.dat</span>
X0 -1.5
Kinv 2.51875
TEMP 3.45625
</pre>

<p>The next task is to actually evaluate the model at this point in
parameter space. This step is typically left up to you because your
modeling program likely has its own way of reading in parameters and
writing outputs. You will need to read in the parameter values in
the <code>parameters.dat</code> files and write results as described
below.</p>

<p>For this tutorial, we have written a little Python
program to generate model outputs from the files and directories
created by <code>madai_generate_training_points</code>. The
 <code>parabolic_evaluate.py</code> program can be found in the
directory <code>DistributionSampling/tutorial/parabolic_example/</code>. To
run it, write</p>

<pre>$ <span class="input">../parabolic_example/parabolic_evaluate.py model_output/run*</span></pre>

<p><code>parabolic_evaluate.py</code> takes as command-line arguments
the names of a directories that contain a file
named <code>parameters.dat</code> and writes a file
called <code>results.dat</code> in each directory.</p>

<p>Verify that it works:</p>

<pre>$ <span class="input">cat ./model_output/run0001/results.dat</span>
MEAN_X 1.88486922161 0.147524825771
MEAN_X_SQUARED 5.87812585509 0.991401491412
MEAN_ENERGY 4.46415150519 0.369616766285</pre>

<div class="box">
<p><em>Aside:</em> It doesn't matter how you populate
the <code>results.dat</code> files.  We expect that for your actual
simulation runs, you will be running the full model on a supercomputer
or on a dozen nodes of a cluster.</p> <p>Also,
the <code>parameters.dat</code> files don't have to be a Latin
hypercube.  You are free to select them using any method.</p></div>

<p>After generating the training points, we compute the principal
component analysis decomposition of the outputs.</p>
<pre>$ <span class="input">madai_pca_decompose .</span></pre>

<p>The file <code>pca_decomposition.dat</code> contains the PCA
data. The eigenvalues are sorted in order of increasing magnitude.</p>

<p>The next step is to generate a Gaussian Process Emulator on the
training points.  The hyper-parameters of the emulator are the
hyper-parameters of the covariance (kernel) functions on the parameter
space and the regression function.  The <code>madai_train_emulator</code>
program generates &ldquo;okay&rdquo; values for the
hyper-parameters by default.</p>

<div class="box">
<p><em>Aside:</em> For more information about covariance functions and
hyperparameters, please see the MADAI Statistics Manual.</p>
</div>

<p>To run the basic training program:</p>

<pre>
$ <span class="input">madai_train_emulator .</span>
</pre>

<p><code>madai_train_emulator</code> writes out a
file called <code>emulator_state.dat</code> which contains hyper-parameters
for each of the retained pca-decomposed sub-models.

<p>One of the Distribution Sampling tools is a program that follows
the same communication protocol as
the <code>parabolic_interactive.py</code> program used in Section
2a. This program, called <code>madai_emulate</code>, can be run
interactively at the command line.</p>

<pre>
$ <span class="input">madai_emulate .</span>
VERSION 1
PARAMETERS
3
X0	UNIFORM	-2	2
Kinv	UNIFORM	0.25	4
TEMP	UNIFORM	0.25	4
OUTPUTS
3
MEAN_X
MEAN_X_SQUARED
MEAN_ENERGY
COVARIANCE
TRIANGULAR_MATRIX
6
END_OF_HEADER</pre>

<p>As with the <code>parabolic_interactive.py</code>
program, <code>madai_emulate</code> waits for the number of parameters
in the model to be written to standard input and writes the model
outputs and covariance to standard output. Below is what you should
see when you enter <code>-0.6 3.5 3.4</code> at the terminal.</p>

<pre>
<span class="input">-0.6 3.5 3.4</span>
2.4367666912344625
9.5582566165380527
3.8049408478401152
0.012703386214090669
-8.7378171278191194e-18
-7.839420506032379e-19
0.41323617041363248
7.7322297868210109e-19
0.08618840459630378</pre>

<p>Now we need to set <code>madai_emulate</code> as
the <code>EXTERNAL_MODEL_EXECUTABLE</code> and set its single argument.

<pre>
$ <span class="input">madai_change_setting . EXTERNAL_MODEL_EXECUTABLE madai_emulate</span>
old: EXTERNAL_MODEL_EXECUTABLE
new: EXTERNAL_MODEL_EXECUTABLE madai_emulate</pre>

<p>It may be possible that an external program requires command-line
arguments. The setting <code>EXTERNAL_MODEL_ARGUMENTS</code>
provides this capability. Arguments should all be specified on
one line and separated by white space. Double quotation marks should
surround arguments with spaces.</p>

<p><code>madai_emulate</code> takes a single argument, the
current working directory. Set that argument as shown below.</p>

<pre>
$ <span class="input">madai_change_setting . EXTERNAL_MODEL_ARGUMENTS .</span>
old: EXTERNAL_MODEL_ARGUMENTS
new: EXTERNAL_MODEL_ARGUMENTS .</pre>

<p>The final step is to run the Markov chain Monte Carlo (MCMC)
routine on the code.  The <code>madai_generate_trace</code> program
uses the trained Gaussian Process model emulator to produce model
outputs for points in parameter space.  These model outputs are
compared to observed values to calculate relative likelihood.</p>

<!-- <p class="centered"><em>L</em> &#8733; exp((-0.5) sum(
((<em>Y<sub>_observed</sub></em>[<em>i</em>] - <em>Y<sub>_model</sub></em>[<em>i</em>]) /
&sigma;[<em>i</em>] ))^<sup>2</sup>)</p> -->

<pre>
$ <span class="input">madai_generate_trace . &quot;mcmc.csv&quot;</span>
</pre>

<pre>
$ <span class="input">head mcmc.csv</span>
&quot;X0&quot;,&quot;K&quot;,&quot;TEMP&quot;,&quot;MEAN_X&quot;,&quot;MEAN_X_SQUARED&quot;,&quot;MEAN_ENERGY&quot;,&quot;LogLikelihood&quot;
-0.167188,1.63734,0.790651,0,0,0,-7.0052
-0.176625,1.60696,0.673026,-0.176625,1.87896,0.673026,-6.89768
-0.181315,1.61748,0.744548,-0.181315,1.89524,0.744548,-6.97992
-0.181315,1.61748,0.744548,-0.181315,1.89524,0.744548,-6.97992
-0.222542,1.62965,0.668291,-0.222542,1.85553,0.668291,-6.85991
-0.188486,1.62792,0.638246,-0.188486,1.84436,0.638246,-6.81262
-0.198998,1.65095,0.659951,-0.198998,1.82891,0.659951,-6.80038
-0.19968,1.6921,0.574281,-0.19968,1.75331,0.574281,-6.61224
-0.19968,1.6921,0.574281,-0.19968,1.75331,0.574281,-6.61224
</pre>

<p>We expect the emulator to be used frequently enough that we have
written <code>madai_generate_trace</code> to use the emulator internally if
<code>EXTERNAL_MODEL_EXECUTABLE</code> is not set or is set to an
empty value. In fact, this the default behavior
of <code>madai_generate_trace</code> is to use the emulator. You may
use the <code>madai_emulate</code> program to access the emulator if
you wish, but it will typically be slower than if you use the built-in
emulator.</p>

<p>To use the internal emulator, run</p>

<pre>
$ <span class="input">madai_change_setting . EXTERNAL_MODEL_EXECUTABLE &quot;&quot;</span></pre>

<p>The <code>madai_generate_trace</code> program will produce the
number of points specified by
the <code>SAMPLER_NUMBER_OF_SAMPLES</code> entry in
the <code>settings.dat</code> file. Depending on the number of the
parameters, a larger or smaller number of samples will need to be
drawn.  Once you are sure that the program is working correctly,
set <code>SAMPLER_NUMBER_OF_SAMPLES</code> to a large number (a
million or more) and let the program run for a while.</p>

<pre>
$ <span class="input">madai_change_setting . SAMPLER_NUMBER_OF_SAMPLES 1000000</span>
old: SAMPLER_NUMBER_OF_SAMPLES 100
new: SAMPLER_NUMBER_OF_SAMPLES 1000000
</pre>

<p>As before, we can generate a scatterplot of the samples generated
from the emulator. Figure 2 shows a side-by-side comparison of two
scatterplot matrices. The one on the left shows the density of samples
from direct execution of the model. The one on the right shows the
density of samples from the Gaussian Process Emulator trained on the
parabolic potential training data. While the bulk of the density is in
the correct place in parameter space on the right scatterplot matrix,
the shape of the distribution is quite different.</p>

<pre>
$ <span class="input">madai_gnuplot_scatterplot_matrix mcmc.csv mcmc.pdf parameter_priors.dat 50</span></pre>

<div class="figure">
  <div class="centered">
    <a href="images/mcmc_fast_50000.png"><img src="images/mcmc_fast_50000.png" width="40%" height="40%"/></a>

    <a href="images/mcmc_emulator_50000_basic.png"><img src="images/mcmc_emulator_50000_basic.png" width="40%" height="40%"/></a>
  </div>
  <div>
    <p>Figure 2: Left - Scatterplot matrix of the parabolic potential
    model sampled directly. Right - Scatterplot matrix of the emulated
    parabolic potential model with basic training of the Gaussian
    Process Emulator enabled.
    </p>
  </div>
</div>

<p>As Figure 2 shows, the default basic training mode offered by the
emulator does not always capture the shape of the high-dimensional
distribution. For better results, we can enable a slightly slower but
more thorough emulator training algorithm.</p>

<p>Change the setting <code>EMULATOR_TRAINING_ALGORITHM</code> to the following:</p>

<pre>
$ <span class="input">madai_change_setting . EMULATOR_TRAINING_ALGORITHM exhaustive_geometric_kfold_common</span></pre>

<p>Now retrain the emulator with</p>

<pre>
$ <span class="input">madai_train_emulator .</span></pre>

<p>and generate a new trace.</p>

<pre>
$ <span class="input">madai_generate_trace . "mcmc_better.csv"</span></pre>

<p>Figure 3 shows the results of the emulator with improved
training. The matrix plot from the samples generated with the emulator
(right plot) matches the scatterplot matrix generated
from the parabolic potential model directly (left plot).</p>

<div class="figure">
  <div class="centered">
    <a href="images/mcmc_fast_50000.png"><img src="images/mcmc_fast_50000.png" width="40%" height="40%"/></a>
    <a href="images/mcmc_emulator_50000_better.png"><img src="images/mcmc_emulator_50000_better.png" width="40%" height="40%"/></a>
  </div>
  <div>
    <p>Figure 3: Left - Scatterplot matrix of the parabolic potential
    model sampled directly. Right - Scatterplot matrix of the emulated
    parabolic potential model with more advanced Gaussian Process
    Emulator training.
    </p>
  </div>
</div>

<h2 id="Visualizing">3. Visualizing the Results</h2>

<h3 id="Slices">3a. Visualizing a Slice of Parameter Space</h3>

<p>The Distribution Sampling tools can also uniformly sample from the
parameter space.  In the next example, the model has four input
parameters, but we want to visualize first, a two-dimensional slice
through parameter space and secondly, a three-dimensional slice.</p>

<p>To produce a <em>slice</em>, set the <code>SAMPLER</code> setting
to <code>PercentileGrid</code> and set
the <code>SAMPLER_INACTIVE_PARAMETERS_FILE</code> setting to point at
a file that specifies which parameters should be <em>inactivated</em>
or locked down to a single constant value.</p>

<p>For this example, first make sure you are in the
<code>DistributionSampling/tutorial</code> directory.

<p>Then make a working directory:</p>

<pre>
$ <span class="input">mkdir slice</span>
$ <span class="input">cd slice</span></pre>

<p>Next, point <code>EXTERNAL_MODEL_EXECUTABLE</code> at the example
program.</p>

<pre>$ <span class="input">madai_change_setting . EXTERNAL_MODEL_EXECUTABLE \
    ../cup_example/cup.py</span></pre>

<p>Set the <code>EXPERIMENTAL_RESULTS_FILE</code> location:

<pre>$ <span class="input">madai_change_setting . EXPERIMENTAL_RESULTS_FILE \
    ../cup_example/experimental_results.dat</span></pre>

<p>Then we set the inactive parameters file,

<pre>$ <span class="input">madai_change_setting . SAMPLER_INACTIVE_PARAMETERS_FILE \
    ../cup_example/inactive_parameters_2d.dat</span></pre>

<p>Let's take a look at the format of the inactive parameters file.
It has one line for each inactive parameter. Each parameter line is
followed by the value that it will be fixed at.  Active parameters are
not listed in this file.</p>

<pre>$ <span class="input">cat ../cup_example/inactive_parameters_2d.dat</span>
x2 0.0
x4 0.0</pre>

<p>Finally, we need to change the sampler method from the
default <code>MetropolisHastings</code>, which returns samples whose
equilibrium distribution is proportional to posterior likelihood, to
<code>PercentileGrid</code>, which (non-randomly) samples from
the <em>prior</em> distribution.  If the prior distribution is a
uniform distribution from 0 to 100, and we ask
the <code>PercentileGrid</code> sampler for 50 samples, it will return
{1,3,5,...97,99}.  If the prior is a Gaussian distribution, then the
samples will be clustered more tightly near the mean of the
distribution.

<pre>$ <span class="input">madai_change_setting . SAMPLER PercentileGrid</span></pre>

<p>Since we have two active parameters, the <code>PercentileGrid</code> sampler will return a rectangular grid of points.  If we want 300 samples in each direction, we will need 300&sup2; samples.

<pre>$ <span class="input">madai_change_setting . SAMPLER_NUMBER_OF_SAMPLES 90000</span></pre>

<p>We will use the same <code>madai_generate_trace</code> program to

<pre>$ <span class="input">madai_generate_trace . grid.csv</span></pre>

<h4>Viewing the Slice</h4>

<p>To visualize this slice, open the <code>grid.csv</code> file in the
MADAI Workbench or ParaView.</p>

<p class="centered"><img src="images/madai_dsl_grid_0.png"></p>

<p>Convert from tabular data to 2-d spacial data using the Table To
Points filter.  Set <code>X</code> and <code>Y</code>
to <code>x1</code> and <code>x3</code>.  Set “2D Points” to “yes”.
After applying the filter, create a new 3D View to see the points in
space. If you zoom in, you should see discrete points.</p>

<p class="centered"><img src="images/madai_dsl_grid_1.png"></p>

Use the Delaunay2D filter to make the points into a surface.  I've
colored this surface with LogLikelihood.

<p class="centered"><img src="images/madai_dsl_grid_2.png"></p>

If you want to see Likelihood rather than LogLikelihood, use the
Calculator filter to calculate it.  I turned on the grid and colored
using the Black-Body Radiation color map.

<p class="centered"><img src="images/madai_dsl_grid_3.png"></p>

<h4>Exercise:</h4>

<p>Make a three-dimensional “slice” through this model's parameter
space.  Hints: you only need to deactivate one parameter; use a
smaller number of samples; use the Delaunay3D filter; and use the
Contour filter to find the high-likelihood region.</p>

<h3 id="PercentileSurfaceFilter">3b. Percentile Surface Filter</h3>

<p>There are limitations to viewing the results of the MCMC sampling
using a scatter-plot matrix, so we will use the MADAI Workbench to
project those points into three dimensions.</p>

<p>First, use <code>madai_subsample_text_file</code> to reduce the
size of your MCMC trace down to about 10000 points.  Then load the CSV
file in the MADAI Workbench.</p>

<p class="centered"><img src="images/madai_dsl_parab_0.png"></p>

<p>After loading the CSV file, convert from tabular data to 3-d
spatial data using the Table To Points filter.  Set <code>X</code>,
 <code>Y</code>, and <code>Z</code> to the three model
parameters <code>X0</code>, <code>K</code>, and <code>TEMP</code>.
After applying the filter, create a new 3D View to see the points in
space.

<p class="centered"><img src="images/madai_dsl_parab_1.png"></p>

<p>In general, the scales for each parameter will not be comparable,
sometimes by many orders of magnitude.  You may need to apply the
Rescale Points Filter<sup title="Only available in the MADAI
Workbench, not ParaView"
style="text-decoration:underline">&#65121;</sup>
to rescale each dimension.

<p class="centered"><img src="images/madai_dsl_parab_2.png"></p>

<p>Understanding the shape of a collection of points in space is
difficult, which is why we provide the Percentile Surface
Filter<sup title="Only available in the MADAI Workbench, not ParaView"
style="text-decoration:underline">&#65121;</sup>, which draws a
surface around the densest part of the point cloud.</p>

<p>To figure out which part of the cloud is densest, the filter does
not calculate density, but makes use of the fact that the density
increases with log(Likelihood).  It simply draws as surface around the
95% of the points with the highest log(Likelihood).  Before running
the filter, be sure that “Point Scalars to Use for Percentile” is set
to LogLikelihood.</p>

<p class="centered"><img src="images/madai_dsl_parab_3.png"></p>

<p>The resulting surface can be colored with one of the other
variables to see the relationship between that variable and the three
parameters we used as spacial dimensions.</p>



<h3 id="OptimalPercentileSurfaceProjection">3b. Optimal Percentile Surface Projection</h3>

<p>The <code>MaximizeNormalizedShapeIndexProjectionFilter</code> will search for a percentile surface projection with the most interesting shape.	</p>


<pre>
$ <span class="input">tar -x -z -f f_gomez_emu_reg0_2013.tar.gz</span>
$ <span class="input">mkdir galaxy</span>
$ <span class="input">cd galaxy</span>
$ <span class="input">cp ../f_gomez_emu_reg0_2013/parameter_priors.dat .</span>
$ <span class="input">cp ../f_gomez_emu_reg0_2013/observable_names.dat .</span>
$ <span class="input">cat &gt; settings.dat &lt;&lt;EOF
MODEL_OUTPUT_DIRECTORY ../f_gomez_emu_reg0_2013/model_output
EXPERIMENTAL_RESULTS_FILE ../f_gomez_emu_reg0_2013/experimental_results.dat
VERBOSE 1
EMULATOR_TRAINING_ALGORITHM exhaustive_geometric_kfold_common
MCMC_NUMBER_OF_BURN_IN_SAMPLES 200
SAMPLER_NUMBER_OF_SAMPLES 1000000
EXTERNAL_MODEL_EXECUTABLE madai_emulate
EXTERNAL_MODEL_ARGUMENTS .
EOF</span>		
$ <span class="input">madai_pca_decompose .</span>
PCA decomposition succeeded.
Wrote PCA decomposition file './pca_decomposition.dat'.
$ <span class="input">nice madai_train_emulator .</span>
Emulator training succeeded.
Wrote emulator state file './emulator_state.dat'.
$ <span class="input">nice madai_generate_trace . mcmc-1000000.csv</span>
Using external model executable 'madai_emulate'.
Using MetropolisHastingsSampler for sampling
Succeeded writing trace file 'mcmc-1000000.csv'.
$ <span class="input">madai_analyze_trace . mcmc-1000000.csv > mcmc-analysis.csv</span>
$ <span class="input">madai_gnuplot_scatterplot_matrix mcmc-1000000.csv mcmc.pdf parameter_priors.dat 100</span>
input:   /d/data/galaxy/mcmc-1000000.csv
output:  /d/data/galaxy/mcmc.pdf
gnuplot file: /tmp/madai_gnuplot_scatterplot_matrix_1jkDqq/scatterplot_matrix.gplt
$ <span class="input">madai_subsample_text_file 10 mcmc-1000000.csv mcmc-100000.csv</span>
$ <span class="input">madai_subsample_text_file 100 mcmc-1000000.csv mcmc-10000.csv</span>
</pre>
<p>Let's open <code>mcmc-10000.csv</code> in the workbench and apply the Maximize Normalized Shape Index Projection filter.</p>

<p class="centered"><img src="images/madai_dsl_optimal_0.png"></p>
<p class="centered"><img src="images/madai_dsl_optimal_1.png"></p>
<p class="centered"><img src="images/madai_dsl_optimal_2.png" width="860"></p>

<hr>

<p>&nbsp;</p>


</div>
</body>
</html>

<!--  LocalWords:  px pre moz dddddd MaxOS RedHat Eigen sudo cmake cd
      LocalWords:  libboost dev libeigen groupinstall devel eigen src
      LocalWords:  MacOS macports mkdir executables EOF PCA py mcmc
      LocalWords:  csv utf os sys Wyka xrange elif sqrt ParaView png
      LocalWords:  GetGaussianIntegral MeanX MeanE ErrorX ErrorE dat
      LocalWords:  rundir params IOError len argv arg tt ffffff th td
      LocalWords:  DistributionSampling cbracket preproc specialchar
      LocalWords:  madai_generate_trace stdout endin PercentileGrid
      LocalWords:  STDDEV ParabolicPotentialModel stdin LogLikelihood
      LocalWords:  pca Cov awk ln MyModel cxx iostream fstream madai
      LocalWords:  ErrorType GetScalarOutputsAndCovariance const cerr
      LocalWords:  GetScalarOutputs AddParameter AddScalarOutputName
      LocalWords:  SetObservedScalarValues outputCovariance ofstream
      LocalWords:  SetObservedScalarCovariance SetStepSize Makefile
      LocalWords:  MetropolisHastingsSampler SamplerCSVWriter Wextra
      LocalWords:  GenerateSamplesAndSaveToFile CXXFLAGS LDFLAGS dsl
      LocalWords:  lDistributionSampling subsample whitespace gnuplot
 -->
<!--  LocalWords:  hyperparameters Delaunay parab
 -->
