<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<title>MADAI Distribution-Sampling Tutorial</title>
<style>
div.column { color:black; background-color:white; margin-left:auto;
	margin-right:auto; margin-top:0px; margin-bottom:0px;
	max-width:640px; text-align:left; padding:8px 8px 8px 8px;
	border:1px solid #56A0D3; }
div.wide { color:black; background-color:white; margin-left:0.5em;
	margin-right:0.5em; padding:0.5em; }
body { color:#000000; background-color:#56A0D3; padding:0; margin:0;
	font-family:sans-serif; text-align:center; background-repeat:
	repeat; background-attachment:fixed; background-size:cover; }
code { color:#001A57;background-color:#ffffff;}
pre .input { color:#001A57; background-color:#f0f0f0; }
pre { color:#000000; background-color:#f0f0f0;
	overflow:auto; overflow-y:visible;
	border-left:2px #dddddd solid; margin-left:15px;
	padding-left:10px; padding-top:2px; padding-bottom:2px;
	margin-top:3px; margin-bottom:3px; z-index:12; }
table { border-collapse:collapse; }
th { color:black; background-color:#f0f0f0;}
td,th { border:1px black solid}
hr { width:100%; background-color:#56A0D3; color:#001A57;
	border:0;height:1px; margin:0}
.centered {text-align:center;}
.cbracket { color:#440044; background-color:#f0f0f0;
	text-decoration:none; font-weight:bold; }
.comment { color:#880000; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.function { color:#008800; background-color:#f0f0f0;
	text-decoration:none; font-weight:bold; }
.keyword { color:#000088; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.normal { color:#000000; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.number { color:#224466; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.preproc { color:#444400; background-color:#f0f0f0;
	text-decoration:underline; font-weight:normal; }
.specialchar { color:#004488; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.string { color:#004444; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.symbol { color:#008844; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
.type { color:#444444; background-color:#f0f0f0;
	text-decoration:none; font-weight:normal; }
</style>
<script>
function toggleViz(name) {
  var e = document.getElementById(name);
  if(e.style.display == 'block') {
    e.style.display = 'none';
  } else {
    e.style.display = 'block';
  }
  return false;
}
</script>
</head>
<body>
<div class="column">
<!--=========================================================================-->
<h1>MADAI Distribution-Sampling Tutorial</h1>
<hr>

<!--=========================================================================-->
<h2>0. Introduction</h2>

<!-- \todo insert background for what we want to accomplish -->

<!--=========================================================================-->
<h2>1. Installing The Software</h2>

<p> Pre-compiled versions of this software can be found here:</p>
<ul>
  <li> MaxOS 32-bit:  <u>href://.....<!-- \todo insert apropriate URLs --></u></li>
  <li> MaxOS 64-bit:  <u>href://.....<!-- \todo insert apropriate URLs --></u></li>
  <li> RedHat 64-bit: <u>href://.....<!-- \todo insert apropriate URLs --></u></li>
  <li> Ubuntu 64-bit: <u>href://.....<!-- \todo insert apropriate URLs --></u></li>
  <li> ... </li>
</ul>

<p>If you can not use one of those sources, you will have to compile
  it yourself.</p>

<ol>
  <li>Install the prerequisite packages
  (<a href="http://www.cmake.org/cmake/resources/software.html">CMake</a>,
  <a href="http://www.boost.org/users/download/">Boost</a>,
  <a href="http://eigen.tuxfamily.org/">Eigen3</a>):
	<ul>
	  <li>Ubuntu/Debian-based:
		<pre>
$ <span class="input">sudo apt-get -y install \
    build-essential \
    cmake \
    libboost-dev \
    libeigen3-dev</span></pre>
	  </li>
	  <li>Red Hat-based:
<pre>
$ <span class="input">sudo yum -y groupinstall "Development Tools"</span>
$ <span class="input">sudo yum -y install \
    cmake \
    boost-devel \
    eigen3-devel</span></pre>
	  </li>
	  <li>MacOS 10.x with macports:
	    <pre>$ <span class="input">port install cmake boost eigen3</span></pre>
	  </li>
	</ul>
  </li>
  <li>Download DistributionSampling.tar.gz (<u>href://.....<!-- \todo insert apropriate URLs --></u>)</li>
  <li>Extract
<pre>
$ <span class="input">mkdir ~/src</span>
$ <span class="input">cd ~/src</span>
$ <span class="input">tar -x -z -f .../DistributionSampling.tar.gz</span></pre></li>
  <li>Make a build directory:
<pre>
$ <span class="input">mkdir ~/build/DistributionSampling</span>
$ <span class="input">cd ~/build/DistributionSampling</span></pre></li>
  <li>Build:
<pre>
$ <span class="input">cmake ~/src/DistributionSampling \
    -DCMAKE_INSTALL_PREFIX:PATH="${HOME}/local"</span> <!--
CORY: make sure the defaults in CmakeLists.txt are for a Release '-O3'
/ no-testing version.
-->
$ <span class="input">make</span>
$ <span class="input">make install</span></pre></li>
</ol>
<p>Your executables will be in the
directory <code>${HOME}/local/bin</code>. You can
make these executables available by including this directory in your
path/:</p>
<pre>$ <span class="input">PATH=&quot;${PATH}:${HOME}/local/bin&quot;</span></pre>

<!--=========================================================================-->
<h2>2. Running the Software With a Fast Model</h2>

<p>By a "fast model" we mean that you can wait while it runs millions
of times.</p>

<p>The program <code>generateMCMCtraceExternal</code> will call your
executable and interactively query it for model outputs at given
parameter vectors.  <code>generateMCMCtraceExternal</code> expects a
certain format, which we will describe.</p>

<ol>
<li>First your program (which we will call the &ldquo;external model&rdquo;) will
output on stdout a list of comments (each beginning with a '#' and
endin with a '\n').</li>
<li>Then it will output the string &quot;VERSION 1 \n&quot;</li>
<li>Then it will output the string &quot;PARAMETERS <em>N</em>
\n&quot;, where <em>N</em> is the number of parameters.</li>
<li>Then, for each parameter, it will output the name of the parameter
(a string without whitespace), whitespace, the prior distribution, and
'\n'
<ul>
<li>A uniform prior distribution is in the format &quot;UNIFORM <em>MIN</em> <em>MAX</em>&quot;</li>
<li>A Gaussian prior distribution is in the format &quot;GAUSSIAN <em>MEAN</em> <em>STDDEV</em>&quot;</li>
</ul></li>
<li>Then the string &quot;OUTPUTS <em>N</em> \n&quot;, where <em>N</em> is the number of outputs.</li>
<li>Then, for each parameter, it will output the name of the output (a string without whitespace), followed by a '\n'</li>
<li>Then it either outputs:
<ul>
  <li>&quot;VARIANCE <em>N</em> \n&quot;, where <em>N</em> is the number of outputs, <br>or</li>
  <li>&quot;COVARIANCE TRIANGULAR_MATRIX <em>M</em> \n&quot;, where <em>M</em>=<em>N</em>&times;(<em>N</em>+1)/2)<br>or</li>
  <li>&quot;COVARIANCE FULL_MATRIX <em>K</em> \n&quot;, where <em>K</em>=<em>N</em>^<sup>2</sup></li>
</ul></li>
<li>&quot;END_OF_HEADER \n&quot; </li>
</ol>

<p>Our example will be the parabolic potential model.  This
model has the parameters <code>X0</code>, <code>K</code>, and <code>TEMP</code>;
and the observables <code>MEAN_X</code>, <code>MEAN_X_SQUARED</code>, and
<code>MEAN_ENERGY</code>.  Here's what the preamble of the interactive
program looks like:</p>

<pre>
$ <span class="input">python parabolic_interactive.py</span>
# ParabolicPotentialModel
VERSION 1
PARAMETERS 3
X0	UNIFORM	-2.0	2.0
K	UNIFORM	0.5	4.0
TEMP	UNIFORM	0.5	10.0
OUTPUTS 3
MEAN_X
MEAN_X_SQUARED
MEAN_ENERGY
VARIANCE 3
END_OF_HEADER
<span class="input">STOP</span></pre>

<p>The external model then waits for a list of parameter values
(encoded as text) on stdin.  Then it returns the model outputs
followed by the model covariances.  For example:

<pre>
<span class="input">0.0 2.25 5.25</span>
0.0 1.166666666666667 5.250000000000001
1.0801234497346435 1.6499158227686113 3.712310601229375
</pre>

<ul>
<li><a href="../parabolic/parabolic_interactive.py">parabolic_interactive.py</a></li>
<li><a href="../parabolic/ParabolicPotentialModel.py">ParabolicPotentialModel.py</a></li>
</ul>

<p>First, choose a working directory:</p>

<pre>
$ <span class="input">DIR=&quot;${HOME}/data/parabolic_ext&quot;</span>
$ <span class="input">mkdir -p &quot;$DIR&quot;</span>
$ <span class="input">cd &quot;$DIR&quot;</span></pre>

<p>From here on out, we will assume that you are in your working
directory and will refer to it as <code>.</code></p>

<p>Next, we  will create a <code>setting.dat</code> file in
  this directory with some default values in it. All of the
  DistributionSampling utilities will look for this file.</p>
<pre>
$ <span class="input">cat &gt; &quot;settings.dat&quot; &lt;&lt;EOF
EXPERIMENTAL_RESULTS_DIRECTORY experimental_results
MCMC_NUMBER_OF_SAMPLES 100
MCMC_NUMBER_OF_BURN_IN_SAMPLES 0
MCMC_USE_MODEL_ERROR 0
MCMC_STEP_SIZE 0.1
EXTERNAL_MODEL_EXECUTABLE <span style="font-family:sans-serif">(path to)</span>/parabolic_interactive.py
EXTERNAL_MODEL_ARGUMENTS
EOF</span></pre>

<p>Next we will specify all of the experimentally observed measurements and errors:</p>

<pre>
$ <span class="input">mkdir &quot;experimental_results&quot;</span>
$ <span class="input">cat &gt; &quot;experimental_results/results.dat&quot; &lt;&lt;EOF
MEAN_X         1.14           0.1
MEAN_X_SQUARED 2.77634418605  0.1
MEAN_ENERGY    3.4925         0.1
EOF</span>
</pre>

<p>If you skip that step, it assumes that the measurements is 0.0 and the error is 1.0.</p>

<p>The final step is to run the Markov chain Monte Carlo (MCMC)
routine on your model.  The <code>generateMCMCtraceExternal</code> program
uses the external model to produce model outputs for points in
parameter space.  These model outputs are compared to the experimental
values to calculate likelihood.</p>

<p class="centered"><em>L</em> &#8733; exp((-0.5) sum(
(<em>Y<sub>_observed</sub></em>[<em>i</em>] - <em>Y<sub>_model</sub></em>[<em>i</em>]) /
&sigma;[<em>i</em>] ))</p>

<p>The Metropolis-Hastings MCMC algorithm is used to draw a large
number of samples from the distribution proportional to likelihood.
These values are stored in a comma-separated-value (csv) file
specified in the arguments.</p>

<pre>
$ <span class="input">generateMCMCtraceExternal . &quot;mcmc.csv&quot;</span>
</pre>

<p>The output file is left in the <code>trace</code> directory:</p>

<pre>
$ <span class="input">head trace/mcmc.csv</span>
"X0","K","TEMP","MEAN_X","MEAN_X_SQUARED","MEAN_ENERGY","LogLikelihood"
-0.687954,3.69012,3.48753,-0.687954,0.945831,3.48753,-11.6557
-0.68372,3.76719,3.42022,-0.68372,0.921423,3.42022,-11.3976
-0.71932,3.75696,3.38807,-0.71932,0.968327,3.38807,-11.3574
-0.624684,3.82671,3.49921,-0.624684,0.847438,3.49921,-11.5668
-0.648931,3.91341,3.55124,-0.648931,0.874838,3.55124,-11.7892
-0.653541,3.92884,3.58919,-0.653541,0.883891,3.58919,-11.9357
-0.626959,3.95924,3.46898,-0.626959,0.831164,3.46898,-11.4492
-0.626959,3.95924,3.46898,-0.626959,0.831164,3.46898,-11.4492
-0.542122,3.93226,3.24617,-0.542122,0.706659,3.24617,-10.5558
</pre>

<p>The <code>generateMCMCtraceExternal</code> program will produce the
 number of points specified in the <code>settings.dat</code> under in
 the <code>MCMC_NUMBER_OF_SAMPLES</code> variable.  Depending on the
 number of the parameters, a larger or smaller number of samples will
 need to be drawn.  Once you are sure that the program is working
 correctly, set <code>MCMC_NUMBER_OF_SAMPLES</code> to a large number
 (10<sup>6</sup> or 10<sup>7</sup>) and let the program run for a
 while.</p>


<!--=========================================================================-->
<h2>3. (Advanced) Linking to the Library</h2>

<p>Another way to interface with the DistributionSampling library is
to link directly to it.  In this example, your model is implemented as
a subclass of the madai::Model class.

<p>MyModel.cxx</p>

<pre><span class="preproc">#include</span><span class="normal"> </span><span class="string">&lt;madai/DistributionSampling/Model.h&gt;</span>
<span class="preproc">#include</span><span class="normal"> </span><span class="string">&lt;madai/DistributionSampling/MetropolisHastingsSampler.h&gt;</span>
<span class="keyword">class</span><span class="normal"> </span><span class="classname">MyModel</span><span class="normal"> </span><span class="symbol">:</span><span class="normal"> </span><span class="keyword">public</span><span class="normal"> madai</span><span class="symbol">::</span><span class="normal">Model </span><span class="cbracket">{</span>
<span class="keyword">public</span><span class="symbol">:</span>
<span class="normal">  </span><span class="function">MyModel</span><span class="symbol">();</span>
<span class="normal">  </span><span class="keyword">virtual</span><span class="normal"> </span><span class="symbol">~</span><span class="function">MyModel</span><span class="symbol">()</span><span class="normal"> </span><span class="cbracket">{}</span>
<span class="normal">  </span><span class="keyword">virtual</span><span class="normal"> madai</span><span class="symbol">::</span><span class="normal">Model</span><span class="symbol">::</span><span class="usertype">ErrorType</span><span class="normal"> </span><span class="function">GetScalarOutputsAndCovariance</span><span class="symbol">(</span>
<span class="normal">      </span><span class="keyword">const</span><span class="normal"> std</span><span class="symbol">::</span><span class="normal">vector</span><span class="symbol">&lt;</span><span class="normal"> </span><span class="type">double</span><span class="normal"> </span><span class="symbol">&gt;</span><span class="normal"> </span><span class="symbol">&amp;,</span><span class="normal"> std</span><span class="symbol">::</span><span class="normal">vector</span><span class="symbol">&lt;</span><span class="normal"> </span><span class="type">double</span><span class="normal"> </span><span class="symbol">&gt;</span><span class="normal"> </span><span class="symbol">&amp;,</span>
<span class="normal">       std</span><span class="symbol">::</span><span class="normal">vector</span><span class="symbol">&lt;</span><span class="normal"> </span><span class="type">double</span><span class="normal"> </span><span class="symbol">&gt;</span><span class="normal"> </span><span class="symbol">&amp;)</span><span class="normal"> </span><span class="keyword">const</span><span class="symbol">;</span>
<span class="normal">  </span><span class="keyword">virtual</span><span class="normal"> madai</span><span class="symbol">::</span><span class="normal">Model</span><span class="symbol">::</span><span class="usertype">ErrorType</span><span class="normal"> </span><span class="function">GetScalarOutputs</span><span class="symbol">(</span>
<span class="normal">      </span><span class="keyword">const</span><span class="normal"> std</span><span class="symbol">::</span><span class="normal">vector</span><span class="symbol">&lt;</span><span class="normal"> </span><span class="type">double</span><span class="normal"> </span><span class="symbol">&gt;</span><span class="normal"> </span><span class="symbol">&amp;,</span><span class="normal"> std</span><span class="symbol">::</span><span class="normal">vector</span><span class="symbol">&lt;</span><span class="normal"> </span><span class="type">double</span><span class="normal"> </span><span class="symbol">&gt;</span><span class="normal"> </span><span class="symbol">&amp;)</span><span class="normal"> </span><span class="keyword">const</span><span class="symbol">;</span>
<span class="cbracket">}</span><span class="symbol">;</span>
<span class="normal">MyModel</span><span class="symbol">::</span><span class="function">MyModel</span><span class="symbol">()</span><span class="normal"> </span><span class="cbracket">{</span>
<span class="normal">  </span><span class="comment">// Insert your code here.</span>
<span class="normal">  </span><span class="comment">// This constructor calls</span>
<span class="normal">  </span><span class="comment">//   this-&gt;AddParameter(),</span>
<span class="normal">  </span><span class="comment">//   this-&gt;AddScalarOutputName(),</span>
<span class="normal">  </span><span class="comment">//   this-&gt;SetObservedScalarValues(), and</span>
<span class="normal">  </span><span class="comment">//   this-&gt;SetObservedScalarCovariance().</span>
<span class="cbracket">}</span>
<span class="normal">madai</span><span class="symbol">::</span><span class="normal">Model</span><span class="symbol">::</span><span class="usertype">ErrorType</span><span class="normal"> MyModel</span><span class="symbol">::</span><span class="function">GetScalarOutputsAndCovariance</span><span class="symbol">(</span>
<span class="normal">    </span><span class="keyword">const</span><span class="normal"> std</span><span class="symbol">::</span><span class="normal">vector</span><span class="symbol">&lt;</span><span class="normal"> </span><span class="type">double</span><span class="normal"> </span><span class="symbol">&gt;</span><span class="normal"> </span><span class="symbol">&amp;</span><span class="normal"> parameters</span><span class="symbol">,</span>
<span class="normal">    std</span><span class="symbol">::</span><span class="normal">vector</span><span class="symbol">&lt;</span><span class="normal"> </span><span class="type">double</span><span class="normal"> </span><span class="symbol">&gt;</span><span class="normal"> </span><span class="symbol">&amp;</span><span class="normal"> scalars</span><span class="symbol">,</span>
<span class="normal">    std</span><span class="symbol">::</span><span class="normal">vector</span><span class="symbol">&lt;</span><span class="normal"> </span><span class="type">double</span><span class="normal"> </span><span class="symbol">&gt;</span><span class="normal"> </span><span class="symbol">&amp;</span><span class="normal"> scalarCovariance</span><span class="symbol">)</span><span class="normal"> </span><span class="keyword">const</span><span class="normal"> </span><span class="cbracket">{</span>
<span class="normal">  </span><span class="comment">// Insert your code here.</span>
<span class="cbracket">}</span>
<span class="normal">madai</span><span class="symbol">::</span><span class="normal">Model</span><span class="symbol">::</span><span class="usertype">ErrorType</span><span class="normal"> MyModel</span><span class="symbol">::</span><span class="function">GetScalarOutputs</span><span class="symbol">(</span>
<span class="normal">    </span><span class="keyword">const</span><span class="normal"> std</span><span class="symbol">::</span><span class="normal">vector</span><span class="symbol">&lt;</span><span class="normal"> </span><span class="type">double</span><span class="normal"> </span><span class="symbol">&gt;</span><span class="normal"> </span><span class="symbol">&amp;</span><span class="normal"> parameters</span><span class="symbol">,</span>
<span class="normal">    std</span><span class="symbol">::</span><span class="normal">vector</span><span class="symbol">&lt;</span><span class="normal"> </span><span class="type">double</span><span class="normal"> </span><span class="symbol">&gt;</span><span class="normal"> </span><span class="symbol">&amp;</span><span class="normal"> scalars </span><span class="symbol">)</span><span class="normal"> </span><span class="keyword">const</span> <span class="cbracket">{</span>
<span class="normal">  </span><span class="comment">// Insert your code here.</span>
<span class="cbracket">}</span>
<span class="type">int</span><span class="normal"> </span><span class="function">main</span><span class="symbol">(</span><span class="type">int</span><span class="symbol">,</span><span class="normal"> </span><span class="type">char</span><span class="symbol">**)</span><span class="normal"> </span><span class="cbracket">{</span>
<span class="normal">  </span><span class="usertype">MyModel</span><span class="normal"> model</span><span class="symbol">;</span>
<span class="normal">  madai</span><span class="symbol">::</span><span class="usertype">MetropolisHastingsSampler</span><span class="normal"> mcmc</span><span class="symbol">;</span>
<span class="normal">  mcmc</span><span class="symbol">.</span><span class="function">SetStepSize</span><span class="symbol">(</span><span class="normal"> </span><span class="number">0.1</span><span class="normal"> </span><span class="symbol">);</span>
<span class="normal">  </span><span class="keyword">return</span><span class="normal"> madai</span><span class="symbol">::</span><span class="normal">Sampler</span><span class="symbol">::</span><span class="function">GenerateSamplesAndSaveToFile</span><span class="symbol">(</span>
<span class="normal">      mcmc</span><span class="symbol">,</span><span class="normal"> </span><span class="symbol">&amp;</span><span class="normal">model</span><span class="symbol">,</span><span class="normal"> </span><span class="string">"out.csv"</span><span class="symbol">,</span><span class="normal"> </span><span class="number">1000000</span><span class="symbol">,</span><span class="normal"> </span><span class="number">0</span><span class="symbol">,</span><span class="normal"> </span><span class="keyword">false</span><span class="symbol">,</span><span class="normal"> </span><span class="keyword">true</span><span class="symbol">);</span>
<span class="cbracket">}</span>
</pre>

<p>Assuming <code>CMAKE_INSTALL_PREFIX</code> was set
to <code>${HOME}/local</code>, here is the Makefile:</p>

<pre><span class="symbol">all:</span><span class="normal"> MyModel</span>
<span class="type">CXXFLAGS =</span><span class="normal"> -O</span><span class="number">3</span><span class="normal"> -Wall -pedantic -I</span><span class="string">"${HOME}/local/include"</span>
<span class="type">LDFLAGS =</span><span class="normal"> -L</span><span class="string">"${HOME}/local/lib/madai"</span><span class="normal"> -lDistributionSampling</span>
<span class="symbol">%</span><span class="normal">.o </span><span class="symbol">:</span><span class="normal"> </span><span class="symbol">%</span><span class="normal">.cxx</span>
<span class="normal">	</span><span class="variable">$(CXX)</span><span class="normal"> -c </span><span class="variable">$(CXXFLAGS)</span><span class="normal"> </span><span class="variable">$&lt;</span><span class="normal"> -o </span><span class="variable">$@</span>
<span class="symbol">%</span><span class="normal"> </span><span class="symbol">:</span><span class="normal"> </span><span class="symbol">%</span><span class="normal">.o</span>
<span class="normal">	</span><span class="variable">$(CXX)</span><span class="normal"> </span><span class="variable">$&lt;</span><span class="normal"> </span><span class="variable">$(LDFLAGS)</span><span class="normal"> -o </span><span class="variable">$@</span>
<span class="preproc">.PHONY :</span><span class="normal"> all</span>
</pre>

<p>&nbsp;</p>

<!--=========================================================================-->
<h2>4. Running the Software With a Slow Model</h2>

<p>The DistributionSampling library uses a Gaussian Proccess Emulator
to emulate a slow model much more quickly.  To train the Emulator, the
software requires hundreds of sample points.  At each training point,
you will need the parameter values and the model outputs.</p>

<p> We will use the parabolic potential model as an example again.
  This model has the parameters <code>X0</code>, <code>K</code>,
  and <code>TEMP</code>; and the observables <code>MEAN_X</code>,
  <code>MEAN_X_SQUARED</code>, and <code>MEAN_ENERGY</code>.</p>

<p>Begin by choosing a working directory:</p>

<pre>
$ <span class="input">DIR=&quot;${HOME}/data/parabolic_emulated&quot;</span>
$ <span class="input">mkdir -p &quot;$DIR&quot;</span>
$ <span class="input">cd &quot;$DIR&quot;</span></pre>

<p>From here on out, we will assume that you are in your working
directory and will refer to it as <code>.</code></p>

<p>The first thing we will do is create a <code>setting.dat</code> file in
  this directory with some default values in it. All of the
  DistributionSampling utilities will look for this file.</p>
<pre>
$ <span class="input">cat &gt; &quot;settings.dat&quot; &lt;&lt;EOF
MODEL_OUTPUT_DIRECTORY model_output
EXPERIMENTAL_RESULTS_DIRECTORY experimental_results
GENERATE_TRAINING_POINTS_NUMBER_OF_POINTS 100
GENERATE_TRAINING_POINTS_PERCENTILE_PARTITION 1
GENERATE_TRAINING_POINTS_STANDARD_DEVIATIONS 3
PCA_FRACTION_RESOLVING_POWER 0.95
EMULATOR_COVARIANCE_FUNCTION SQUARE_EXPONENTIAL_FUNCTION
EMULATOR_REGRESSION_ORDER 1
EMULATOR_NUGGET 0.001
EMULATOR_AMPLITUDE 1
EMULATOR_SCALE 0.01
MCMC_NUMBER_OF_SAMPLES 100
MCMC_NUMBER_OF_BURN_IN_SAMPLES 0
MCMC_USE_EMULATOR_COVARIANCE 0
MCMC_STEP_SIZE 0.1
EOF</span>
</pre>
<p><a href="" onclick="return toggleViz('settings_options');">A detailed description of options in <code>settings.dat</code></a></p>
</div>
<div class="wide" id="settings_options" style="display:none;">
<p style="text-align:center"><b>Options in <code>settings.dat</code></b></p>
<table style="width:100%">
<tr><th>Variable Name</th><th>Default Value</th><th>meaning</th></tr>
<tr><td><code>MODEL_OUTPUT_DIRECTORY</code></td>
  <td>model_output</td>
  <td>The directory (relative to the working directory) where the model inputs and outputs can be found.</td></tr>
<tr><td><code>EXPERIMENTAL_RESULTS_DIRECTORY</code></td>
  <td>experimental_results</td>
  <td>The directory (relative to the working directory) where the experimental observations can be found.</td></tr>
<tr><td><code>GENERATE_TRAINING_POINTS_NUMBER_OF_POINTS</code></td>
  <td>100</td>
  <td>The number of training points generated by <code>generateTrainingPoints</code></td></tr>
<tr><td><code>GENERATE_TRAINING_POINTS_PERCENTILE_PARTITION</code></td>
  <td>1</td>
  <td>If the prior distribution for a parameter is not uniform, should the training points be percentiles from the distribution, or should they be evenly spaced?</td></tr>
<tr><td><code>GENERATE_TRAINING_POINTS_STANDARD_DEVIATIONS</code></td>
  <td>3</td>
  <td>If the prior distribution for a parameter is Gaussian, how far out should the uniformly-spaced sampled points go?</td></tr>
<tr><td><code>PCA_FRACTION_RESOLVING_POWER</code></td>
  <td>0.95</td>
  <td>When <code>basicTrain</code> is deciding how many principal components to retain, it considers the total resolving power of the model.  The resolving power of a single principal component is &radic;(1 + &lambda;[i]), where &lambda;[i] is the eigenvalue associated with that variable.  The total resolving power is the product the resolving powers of all of the components.  <code>basicTrain</code> will retain enough components to keep this fraction of the resolving power.
</td></tr>
<tr><td><code>EMULATOR_COVARIANCE_FUNCTION</code></td>
  <td><code>SQUARE_EXPONENTIAL_FUNCTION</code></td>
  <td>See <u>Covariance Functions<!-- \TODO add link to document --></u></td></tr>
<tr><td><code>EMULATOR_REGRESSION_ORDER</code></td>
  <td>1</td>
  <td>The assumed functional form of the model before Gaussian Process Emulation.  This is the order of the polynomial.  0, 1, 2,or 3. </td></tr>
<tr><td><code>EMULATOR_NUGGET</code></td>
  <td>0.001</td>
  <td>See <u>Covariance Functions</u><!-- \TODO add link to document --></td></tr>
<tr><td><code>EMULATOR_AMPLITUDE</code></td>
  <td>1</td>
  <td>See <u>Covariance Functions</u><!-- \TODO add link to document --></td></tr>
<tr><td><code>EMULATOR_SCALE</code></td>
  <td>0.01</td>
  <td>See <u>Covariance Functions</u><!-- \TODO add link to document --></td></tr>
<tr><td><code>MCMC_NUMBER_OF_SAMPLES</code></td>
  <td>100</td>
  <td>How many samples should <code>generateMCMCtrace</code> produce.  The default is small for testing purposes.  Values around 10<sup>6</sup> are recommended.</td></tr>
<tr><td><code>MCMC_NUMBER_OF_BURN_IN_SAMPLES</code></td>
  <td>0</td>
  <td>What does this do???</td></tr>
<tr><td><code>MCMC_USE_EMULATOR_COVARIANCE</code></td>
  <td>0</td>
  <td>Should the variance returned by the Gaussian Process Emulator be used in the likelihood calculation?</td></tr>
<tr><td><code>MCMC_STEP_SIZE</code></td>
  <td>0.1</td>
  <td>How big should each step be in the Metropolis Hastings
  algorithm?  (This will be scaled by the characteristic length of
  each parameter's prior distribution)</td></tr>
</table>
<p>[<a href="" onclick="return toggleViz('settings_options');">close</a>]</p>

</div>
<div class="column">

<p>Next, we need to create a parameter_priors.dat file that contains
our assumptions about prior probability distribution for the values for
the parameters.
<pre>
$ <span class="input">cat &gt; &quot;parameter_priors.dat&quot; &lt;&lt;EOF
uniform X0   &#0045;2.0 2.0
uniform K    0.5  4.0
uniform TEMP 0.5  10.0
EOF</span>
</pre>

<p>Next we will specify all of the experimentally observed measurements and errors:</p>
<pre>
$ <span class="input">mkdir &quot;experimental_results&quot;</span>
$ <span class="input">cat &gt; &quot;experimental_results/results.dat&quot; &lt;&lt;EOF
MEAN_X         1.14           0.1
MEAN_X_SQUARED 2.77634418605  0.1
MEAN_ENERGY    3.4925         0.1
EOF</span>
</pre>

<p>Finally, we create a file that contains the list of observables
that we want to make use of.  This should be a subset
of <code>results.dat</code>.</p>
<pre>
$ <span class="input">cat &gt; &quot;observable_names.dat&quot; &lt;&lt;EOF
MEAN_X
MEAN_X_SQUARED
MEAN_ENERGY
EOF</span>
</pre>

<p>We are now ready to run the first Distribution-Sampling
utility, <code>generateTrainingPoints</code>.  This program will generate
a Latin hypercube in the parameter space.  The number of sample points
is set by the <code>GENERATE_TRAINING_POINTS_NUMBER_OF_POINTS</code>
variable. (The command-line argument is the name of the working
directory.)</p>
<pre>
$ <span class="input">generateTrainingPoints .</span>
</pre>

<p>The output of <code>generateTrainingPoints</code> is a series of
files <code>model_output/run*/parameters.dat</code>.  For example:</p>

<pre>$ <span class="input">cat ./model_output/run0001/parameters.dat</span>
X0 1.18
K 2.6875
TEMP 9.2875</pre>

<p>The next task is to actually evaluate the model at this point in
parameter space.  To that end, we have written a little Python program
  to do just that.</p>

<ul>
<li><a href="../parabolic/parabolic_evaluate.py">parabolic_evaluate.py</a></li>
<li><a href="../parabolic/ParabolicPotentialModel.py">ParabolicPotentialModel.py</a></li>
</ul>

<p><code>parabolic_evaluate.py</code> takes as command-line arguments the names of
a directory that contains a file <code>parameters.dat</code> and write a
file called <code>results.dat</code>.</p>

<pre>
$ <span class="input">python parabolic_evaluate.py &quot;model_output&quot;/run*</span>
</pre>

<p>After generating the training points, we generate the principal
component analysis decomposition of the outputs.</p>
<pre>$ <span class="input">PCADecompose .</span></pre>

<p>The file <code>pca_decomposition.dat</code> contains the PCA data.  The
eigenvalues are sorted in increasing order.</p>

<p>The next step is to generate a Gaussian Process Emulator on the
training points.  The hyper-parameters of the emulator are the
hyper-parameters of the covariance (kernel) functions on the parameter
space and the regression function.  The <code>basicTrain</code> program
that generates &ldquo;okay&rdquo; values for the hyper-parameters.  The
  default is a square exponential function:</p>

<p class="centered">dist(<em>u</em>,<em>v</em>) = sqrt(sum( ((<em>u</em>[<em>i</em>]-<em>v</em>[<em>i</em>]) / &theta;[<em>i</em>+2])^<sup>2</sup> ))</p>
<p class="centered">Cov(<em>u</em>,<em>v</em>) = &theta;[0] exp( (-0.5) dist(<em>u</em>,<em>v</em>)^<sup>2</sup>) + &theta;[1] &delta;[<em>u</em>,<em>v</em>]</p>

<p>Where <em>u</em> and <em>v</em> are points in parameter space, &theta; is a list of hyper-parameters and &delta; is the Kronecker delta.</p>

<p>By default, the nugget (&theta;[1]) is 0.001 and the amplitude
(&theta;[0]) is 1.0.  We define the characteristic length scale of a
parameter value as the difference between the 75th percentile and the
25th percentile of the prior distribution.  For a uniform prior, this
is half the range.  The default value for &theta;[2+<em>i</em>] the
characteristic length scale of the <em>i</em>th parameter times
  the <code>EMULATOR_SCALE</code> option.</p>

<p>(In the future we plan on providing robust software to search for more
  optimal hyper-parameters.)</p>

<p>To run the basic training program:</p>

<pre>
$ <span class="input">basicTrain .</span>
</pre>

<p><code>basicTrain</code> writes out a file <code>emulator_state.dat</code>
which contains hyper-parameters for each of the retained pca-decomposed
sub-models.

<p>The final step is to run the Markov chain Monte Carlo (MCMC)
routine on the code.  The <code>generateMCMCtrace</code> program uses the
trained Gaussian Process model emulator to produce model outputs for
points in parameter space.  These model outputs are compared to
  observed values to calculate likelihood.</p>

<p class="centered"><em>L</em> &#8733; exp((-0.5) sum(
(<em>Y<sub>_observed</sub></em>[<em>i</em>] - <em>Y<sub>_model</sub></em>[<em>i</em>]) /
&sigma;[<em>i</em>] ))</p>

<p>The Metropolis-Hastings MCMC algorithm is used to draw a large
number of samples from the distribution proportional to likelihood.
These values are stored in a comma-separated-value (csv) file
specified in the arguments.</p>

<pre>
$ <span class="input">generateMCMCtrace . &quot;mcmc.csv&quot;</span>
</pre>

<p>The output file is left in the <code>trace</code> directory:</p>

<pre>
$ <span class="input">head trace/mcmc.csv</span>
"X0","K","TEMP","MEAN_X","MEAN_X_SQUARED","MEAN_ENERGY","LogLikelihood"
-0.167188,1.63734,0.790651,0,0,0,-7.0052
-0.176625,1.60696,0.673026,-0.176625,1.87896,0.673026,-6.89768
-0.181315,1.61748,0.744548,-0.181315,1.89524,0.744548,-6.97992
-0.181315,1.61748,0.744548,-0.181315,1.89524,0.744548,-6.97992
-0.222542,1.62965,0.668291,-0.222542,1.85553,0.668291,-6.85991
-0.188486,1.62792,0.638246,-0.188486,1.84436,0.638246,-6.81262
-0.198998,1.65095,0.659951,-0.198998,1.82891,0.659951,-6.80038
-0.19968,1.6921,0.574281,-0.19968,1.75331,0.574281,-6.61224
-0.19968,1.6921,0.574281,-0.19968,1.75331,0.574281,-6.61224
</pre>

<p>The <code>generateMCMCtrace</code> program will produce the number of
 points specified in the <code>settings.dat</code> under in
 the <code>MCMC_NUMBER_OF_SAMPLES</code> variable.  Depending on the
 number of the parameters, a larger or smaller number of samples will
 need to be drawn.  Once you are sure that the program is working
 correctly, set <code>MCMC_NUMBER_OF_SAMPLES</code> to a large number
 (10<sup>6</sup> or 10<sup>7</sup>) and let the program run for a
  while.</p>

<h2>3. Visualizing the Results</h2>

<p>While visualization software is capable of displaying ten million
points in space, for analysis you may need to reduce the number of
points.  To keep the same random distribution, it may be easiest to
pick out every <em>N</em>th line.  For example, to reduce ten million
points down to ten thousand, pick out every 1000th line:</p>

<pre>
$ <span class="input">awk 'NR % 1000 == 1' &lt; trace/mcmc.csv &gt; trace/mcmc-subsample.csv</span>
</pre>

<p>CSV files can be opened in ParaView or the MADAI Workbench.</p>

<p>&nbsp;</p>


<hr>

</div>
</body>
</html>

<!--  LocalWords:  px pre moz dddddd MaxOS RedHat Eigen sudo cmake cd
      LocalWords:  libboost dev libeigen groupinstall devel eigen src
      LocalWords:  MacOS macports mkdir executables EOF PCA py mcmc
      LocalWords:  generateTrainingPoints PCADecompose basicTrain csv
      LocalWords:  generateMCMCtrace utf os sys Wyka xrange elif sqrt
      LocalWords:  GetGaussianIntegral MeanX MeanE ErrorX ErrorE dat
      LocalWords:  rundir params IOError len argv arg tt ffffff th td
      LocalWords:  DistributionSampling cbracket preproc specialchar
      LocalWords:  generateMCMCtraceExternal stdout endin whitespace
      LocalWords:  STDDEV ParabolicPotentialModel stdin LogLikelihood
      LocalWords:  pca Cov awk
 -->
